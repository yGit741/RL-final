{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLapsBtwOO6m"
   },
   "source": [
    "# Final RL Project - DEEP Reinforcements Learning in MultiRoom Environment\n",
    "\n",
    "Dear students,<br> this is the template notebook. Please copy it by clicking on the \"File\" tab and then on \"Save a copy into drive\".\n",
    "\n",
    "---\n",
    "\n",
    "Name and ID:  \n",
    "Student 1: 204266191\n",
    "<br>\n",
    "Student 2: 318947470\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-OzvtfyOYL8"
   },
   "source": [
    "## Pre-Requisit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEFhAxcrOhB1"
   },
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "import pyvirtualdisplay\n",
    "import IPython\n",
    "import base64\n",
    "import gymnasium\n",
    "import minigrid\n",
    "from minigrid.wrappers import RGBImgObsWrapper, RGBImgPartialObsWrapper, ImgObsWrapper, FullyObsWrapper, RGBImgPartialObsWrapper\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "print(\"Global dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our project imports\n",
    "from minigrid.envs import MultiRoomEnv\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tqdm\n",
    "from cv2 import cvtColor\n",
    "from pathlib import Path\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple, List, Deque  \n",
    "\n",
    "print(\"Local dependencies loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import display_functions\n",
    "import env_functions\n",
    "from display_functions import show_full_frame_rgb, show_partial_greyscale, show_state_full_and_partial\n",
    "from env_functions import create_multiroom_env, get_action_meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diKi1gEQtM3M"
   },
   "outputs": [],
   "source": [
    "# Constants for the environemnt configuration do no change the values\n",
    "highlight = False\n",
    "render_mode = \"rgb_array\"\n",
    "WORK_DIR = Path(\"C:/Users/ASUS/OneDrive/MSc MLDS/Reinforcement Learning/Projects/final-project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnksgjjqOq02"
   },
   "source": [
    "### Display utils\n",
    "\n",
    "The cell below contains the video display configuration. No need to make changes here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceUl4Q9JOzpO"
   },
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)\n",
    "\n",
    "# display = pyvirtualdisplay.Display(visible=0, size=(1400, 900), backend=None).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76Bi4SEyip5J"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "A\n",
    "For this project, you will work with environments from the [MiniGrid](https://minigrid.farama.org) framework. MiniGrid is designed to test and benchmark reinforcement learning algorithms, offering a diverse range of tasks with varying levels of complexity.\n",
    "\n",
    "MiniGrid environments are built around the concept of a partially observable, grid-based world where an agent operates to achieve predefined objectives.\n",
    "\n",
    "### **MultiRoom Environment**\n",
    "\n",
    "You will work with the **MultiRoom Environment** see docomentation [here](https://minigrid.farama.org/environments/minigrid/MultiRoomEnv/). MultiRoomEnv introduces a level of complexity beyond simple navigation tasks by requiring the agent to navigate through multiple connected rooms to reach a goal. This environment is an excellent testbed for reinforcement learning algorithms that require exploration, memory, and planning.\n",
    "\n",
    "### Wrapper Usage\n",
    "\n",
    "To apply a wrapper, you can modify your environment setup as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "kZCKkKFiu-IV",
    "outputId": "0357caae-df4c-4f67-e0ed-df568302324c"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "env = gymnasium.make(\"MiniGrid-MultiRoom-N6-v0\", render_mode=render_mode, highlight=highlight)\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "env = ImgObsWrapper(env)\n",
    "obs, _ = env.reset()\n",
    "axs[1].imshow(obs)\n",
    "axs[1].title.set_text(f'RGBImgPartialObsWrapper, shape: {obs.shape}')\n",
    "axs[0].imshow(env.render())\n",
    "axs[0].title.set_text(f'Full state')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ydi5m69RBSs"
   },
   "source": [
    "### Initializing the smaller environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "QFEJ9keiRLUB",
    "outputId": "116a1126-2f62-4c47-d03f-07d8476ec4db"
   },
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"MiniGrid-MultiRoom-N2-S4-v0\", render_mode=render_mode, highlight=highlight)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "env = ImgObsWrapper(env)\n",
    "obs, _ = env.reset()\n",
    "axs[0].imshow(env.render())\n",
    "axs[0].title.set_text(f'MiniGrid-MultiRoom-N2-S4-v0')\n",
    "\n",
    "\n",
    "\n",
    "env = gymnasium.make(\"MiniGrid-MultiRoom-N4-S5-v0\", render_mode=render_mode, highlight=highlight)\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "env = ImgObsWrapper(env)\n",
    "obs, _ = env.reset()\n",
    "axs[1].imshow(env.render())\n",
    "axs[1].title.set_text(f'MiniGrid-MultiRoom-N4-S5-v0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiHHFwv2ZBd7"
   },
   "source": [
    "### Partial Observation Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "7gwWN2ANYmAR",
    "outputId": "d23f960c-6ee9-44ad-e54e-4b26062ccd14"
   },
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"MiniGrid-MultiRoom-N6-v0\", render_mode=render_mode, highlight=highlight)\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "env = ImgObsWrapper(env)\n",
    "# video_filename = '/content/vid_partial.mp4'\n",
    "video_filename = \"C:/Users/ASUS/OneDrive/MSc MLDS/Reinforcement Learning/Projects/final-project/videos/vid.mp4\"\n",
    "truncated = False\n",
    "# Evaluation\n",
    "with imageio.get_writer(video_filename, fps=10) as video:\n",
    "  obs, _ = env.reset()\n",
    "  done = False\n",
    "  total_reward = 0\n",
    "  step = 0\n",
    "  while not truncated:\n",
    "      action = env.action_space.sample()\n",
    "      obs, reward, done, truncated  , _ = env.step(action)\n",
    "      next_obs = obs  # Get agent's position directly from the environment\n",
    "      video.append_data(obs)\n",
    "      step += 1\n",
    "      if truncated:\n",
    "        print(\"done\",\"reward=\", total_reward,\"num_of_steps=\",step)\n",
    "        break\n",
    "embed_mp4(video_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-GqBbW31xxx"
   },
   "source": [
    "# Our Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_N_steps(env, N, policy=None):\n",
    "    \"\"\"\n",
    "    Runs N steps in the environment, rendering each step.\n",
    "\n",
    "    Parameters:\n",
    "        env: The environment instance.\n",
    "        N (int): Number of steps to execute.\n",
    "        policy (function): Function that takes obs and returns an action. Defaults to random.\n",
    "    \"\"\"\n",
    "    if policy is None:\n",
    "        policy = lambda obs: random.choice([0,1,2,5])  # Default to random actions\n",
    "\n",
    "    obs, _ = env.reset()  # Ensure the environment starts correctly\n",
    "\n",
    "    for i in range(N):\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"Step {i}\")\n",
    "\n",
    "        action = policy(obs)  # Get action from policy\n",
    "        print(f\"Action taken: {action} ({get_action_meaning(action)})\")\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        show_full_frame_rgb(env, obs)\n",
    "        show_partial_greyscale(env, obs)\n",
    "\n",
    "\n",
    "\n",
    "        if done or truncated:  # Reset if the episode ends\n",
    "            print(\"Environment reset!\")\n",
    "            obs, _ = env.reset()\n",
    "env\n",
    "# verification\n",
    "show_N_steps(env, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments like MiniGrid MultiRoom require the agent to understand spatial dependencies and remember past observations to make optimal decisions. However, standard observations only provide a single frame, making it difficult for the agent to infer motion, detect doors opening, or track past locations. In order to deal with this, especially to encourage the agent to learn the process of open door and moving to the next room, we will implement FrameStackPreprocess. In addition, this class will convert the observation to greyscale becasue the RGB channels doesn't contribute to the learning process and do downsampling to better efficency and generalization (we don't need the fine details of the environment).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJuFJREFUeJztncuOXde5nVfdWRfWlcUqFUskxboY7h0DPkCAIHAn7fTyTHmCPEdaabgRJ8HpnCStdA5gwLYoiqTEm3gRRVO2pBV8G1qBkpMZj3+Rq1Syvw/ZEHDyrzXHvI29VdaYc67v+74TEZF/xvw//z+JiAhokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRBosdiG/+tWvus8//zwt7w4PD0v1u7u73evXr7s//elPUf3y8nK3vr7ePX/+fDJNe3t73atXr7o///nPUf2VK1dmnxcvXsRtHBwcdI8ePYrrr127Nuvzt99+G9Wvrq52S0tLs34kzM3NddevXy9p2t/f7549e9Z99913UT3zNj8/33355ZeTaaL+6dOnsaaNjY3ZP1mDCehnLh4/flyaa+rT8NrVq1dn8/zmzZuofmFhYbaPnjx5UtJUGdetra3ZHv3jH/8Y1S8uLnbb29uzuZhqn/J+9Hz99dfxM7/97W+zwj7k/PycWY0/1frj4+N+dXU1rl9bW5s9M6Wmmzdv9isrK3H9xsZGf3R0NKmm27dv90tLS3H95uZmf3BwUGrj7OysVH/nzp1+cXExrt/Z2en39/fj+rm5uf709LSk6eTkpJ+fn4/r9/b2+t3d3bh+YWFh1kZ1XOlLWs8YbW9vx/XMAXMx5VwfHh72V69ejeuXl5dna3bKPcGeW19fLz2T4r9ii4g00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRN41i00+skK1ngwpmcpqFnttbW0yTWSxycNWs9hDrncKTeR/6fM333wTZ7EZKzK0ldwz/6xksVdWVuJ8+JDF3tnZKWnimRTqyaBXs9iMbyWLTf65knvmuTSLvbm5OZvnahab/PNUmrZGZrFZg1PtCd7PXq1ksWPMYrc/ZrGzj1nsfFzNYnd/8WMWW0TkJ4AGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSIA5tkvE8Pj7upqof8rxpnrKaeR6jiawtWdI0H07umZx0mhkmYzxGE6RZbHLP5GDJJU+liRwsOew0i02+nTFivhOoHaOJDH2axSb3DGm2n9xzNf879CHNPZMxZp7Tdc5aRVO6XgdNH374Yaxpd3e3e/v2bZztZ93xTLpehzaqc806T/PhkxgkF6pzOXwKk1upZ7M8f/487iRmxKROqYk2vvjii3gTMEkshEobLLRKPW2gKT1Ag83Cl0naBgaJWVQ0sYHRlG4CjBSDSdvAIGmjook+oCk1bdYSH9ZgAvox0+pcoyk1beaCeX758mVskJW5HjRRnxrkwsLCbI9++eWXUf3w5TzlPuX96Pnqq6+6H80gKyd4jKnHhKhPn2HxDM9MrSk1SBYPC+IiNKUGyeJhrKbUNNSnBskmZjNX5nrMOHEKTmpG/CrCJNI2mOsx44Sm1IzQxDxXTs4Zq2mqffrtt99eOu+o4N8gRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUTeNUlDQqRyB3W1nnQF0b70PmZqiSdOqWl4f3r38UVqSpM0aGJs0zYY/zGaaCeN9Q1Jmoqm6rgO9WmSBk3VLPbYuU6TNMM4pdlqaseup5QrV67MxjSda5JcU+8JNDFG6bhOYpBkgAmRT1VP1pYOprE+Bp1DDyqHBVQ18X7icxUz4pPWjx2nnZ2dONbHQmOs0gU9tDFmrtM2eD8Gky5oDHLs+qscVoGe9AuafPhYTWm/0TTk1hOoGzt3lT2xvLw8+6SmfRGamI/hS+5HMUhC/Pfv349fzMas1AMB9TRPyfsxxyk1MeiPHj2KTZiFwKJ++PDhZJpYcA8ePIhNGD2YNv1Iob6iic2CptS0MXj68eTJk9IvyIqmoT41SE6Ewbg4TCI1I34dVTQN45oaJOuOeX7x4kVUz5iia4ymlG+++WZ2KETlsAqYcp8yxxzoMcVhFf4NUkSkgQYpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYp/wdp1E7+dpn7G1ojcdTw8PCw9OJqPdlL7sNNg/lEmMhsVkLtVU3Ez8h5prE+sqB80ovex2i6du1a6WAIaonEpRe9s/ivX79e2gT7+/ulvDfzRoyTyGFFE8+kUE+/06jhMGeMbwJaqE1z0nBwcDB7Lo0asvYY0/RaVrSwj4gcVjRV5npra6t0LSta2NdpdnvMnuD97NXKuQwxfcj5+TmzGn+q9cfHx/3q6mpcv7a2NntmSk03b97sV1ZW4vqNjY3+6OhoUk23b9/ul5aW4vrNzc3+4OCg1MbZ2Vmp/s6dO/3i4mJcv7Oz0+/v78f1c3Nz/enpaUnTyclJPz8/H9fv7e31u7u7cf3CwsKsjeq40pe0njHa3t6O65kD5mLKuT48POyvXr0a1y8vL8/W7JR7gj23vr5eeibFf8UWEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINIhDm2Qdb9261U1ZT244zWKT/R3uV55KExljMqSVLPaQfZ5SE3neNPdMVp0+VO4MRlM6D0AmmXxxmnsmi828pTl6ssK0UblvnHrGqJJ7/uE/0yx2etXtMK70IdVE7pn3pzl6xnTodwr1lbne3t6eZZ4rWezKXeBj9gTvZ97evn3b/WgG+erVq+7zzz+PX4x5VeqZXO4krtyLzWKbUhNG9/jx49K92NU2MItKPWaHpsq92Jgjz6RmVNU0vD81CzYZG+fp06exGfHFU9FEPZpSsxhMonIvNl/SFU2sWe4nT79IGE/mmTufExhT1mx1/aEpNbC+72eHZ1TuxWb+ptynrFn8aYp7sWODZKIqp2VU61mg1KfPsEAvmyYWJ5um0gabYEwfUoOklgU65TgN9alBMq6YRNoGG2CMJn5RpGaEJjb/lOuP8UFTakZoqrTBl8HYcZpqT/R9f+n2aQX/Biki0kCDFBFpoEGKiDTQIEVEGmiQIiINNEgRkQYapIhIAw1SRKSBBiki8q5Jmup9z9V6omFDRjet5zO1JurTbDX6q5qGTHlVU5qkQVOl36RWxsw17VTy4cxz2gZJoLHrL03SoInUR5pLRn9V0zDXaZJmiNOmCSWihmPGiRxzqml1dXX2z7SevTN2nFLQxBhV7veexCDJ9U5Vz2Kgk+kF4wwiAzOlpsGMaCutpx/VNqr1LOh006AH/VOPE/WpQQ5fhGkfWPhjxon6ygEalQM3hnz4GE2puaCpchgGYzpmT6QHdPxw7uh/atpjxyll+HKjrfdN/MYXL150Dx8+jF+MsVTqGfBnz56VD6uYUhMDTpC/clgFEzulJr5APvvss9JhFSw4+lHZBBVNbDI0pZt5Z2dnNrZPnjwpGWRF01CfGh5zzCarHlZR0TSMa2qQzDEf9l7lsIoxmlK+++672aEQ1cMqptwTwIEeUxxW4d8gRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQuu0FOkaP8a9VU0VXtw2Xt85hnfup9vwg9fw3jNKWmOGp4cHBQevHh4WGpnsu/uSA9PSyACBMxqfTy+TGauMC8kocd8uGVoH11XLnonWhfmntGD/Gz9PL5QVNlwe3v78/mo3IwBFE9IocJaKGNNP8L169fn7WRxvqGQySY8wS0MBfp4SrDuPJcqomMNPPMPdQJaGEfVTLJ1fW3tbU1i2WmV8WihXvQ0zMWxmji/USUp7j2lcmKOD8/Z1bjT7X++Pi4X11djevX1tZmz0yp6ebNm/3Kykpcv7Gx0R8dHU2q6fbt2/3S0lJcv7m52R8cHJTaODs7K9XfuXOnX1xcjOt3dnb6/f39uH5ubq4/PT0taTo5Oenn5+fj+r29vX53dzeuX1hYmLVRHVf6ktYzRtvb23E9c8BcTDnXh4eH/dWrV+P65eXl2Zqdck+w59bX10vPpFyaf8UWEblsaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg3i0Ca50zQnPbae3HOapxwuF6/kTquayP/STnrFKrlnPmnulIxxVRMZY/pcuRcbPcOF74km+p32edDEc2k+nHkjN8x8J5BfRlPljmjqK/dcD/dVp/cxD5rSPgNzTR/SLDa5Z+rJGicwprSR9hmGcU017ezszPZomg/nHIA0cz9AH1h/qSby58xbmg+vELvL8+fPuwcPHsQvZmNW6oE7iSv3YjPwlTYwiUo9m+Dx48ele7E5YIA7ohMwFQ6eqGjCHLkzuHIvNm3Qj6k0YcBoSg2MDU8/nj59Gs8DbVQ0DXdWpwbG5qrei83mr2hiXCt3dfPFWb0Xm7EasydSM/rmm29m5li5F5v+VjXdv38/ruf9r169muRe7NggWWiVXxUM5Jj69Bnqqm2M7cNPXRMb5yLmLjXIoS5tA9MeowmDSc1o+MWStsF7x8w1mlIzGuY5bYP3jllPlX+D+aa4/oZ/s7hMe6KCf4MUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEXnXJA3xnzSnOqaeXC7/RT/xrfT9xA2n1DS8P40aDvd0p22QMhirKU0NEH0kdncRmtIkzZDFTseV+NwYTWSZK/lwkihpH9A/Zk+gKU33oIl5TutJTI3VlKZ71tfXZ/OR3pvOfp56n6KJMarcUf7eDZKOpgceQOWAhKGerGo68NSy8SttVPvA+2knvbD+IjQN45Qe0oGeiibGvzp39AFNqRmhZzCYqTWl5oImTCJtY8iHj9GUmtEwTumXIbVj9h31FU3995HGtM9jxmnMnkj7MIlBEgZ/9OhR/GK+lSr1DMqzZ89Kh1UwSVNqYjFUD6vgm29KTSwcNFUOq+CZShv86qzU8w2OpvTXF/+mgME/efIkNkjGtqJpqE8NcjjRpnJYBWuwomlYG+lGRnv1sAqMoqrp888/j+vn5uZmh0JUDqtA15R7grl4+fLlJIdV+DdIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZF3Ncg0Avgu9ZVnpn7/RWmqMkbTlPVj25jy/Zd1nIbnptQ0Rs9l0wQXMRfvNWrI5fCVC8mr9cPl3+kVlESYiJNVMptVTXt7e7MYXRrrI+bFh2dSDg4OShlSLnqnjTTWx/gwVsQHE1hoVU2MK1HRNJ87HHjA/dipJtqoQB+IoFUOhhjWYQL6ueC+sjHRRH06tsMBILSTQH/RXzm0AU2Qatra2prt0TQSTMyQeU4PoRk0Vdbfzs7O7JNGgkv0Iefn5yiOP9X64+PjfnV1Na5fW1ubPTOlpps3b/YrKytx/cbGRn90dDSpptu3b/dLS0tx/ebmZn9wcFBq4+zsrFR/586dfnFxMa7f2dnp9/f34/q5ubn+9PS0pOnk5KSfn5+P6/f29vrd3d24fmFhYdZGdVzpS1rPGG1vb8f1zAFzMeVcHx4e9levXo3rl5eXZ2t2yj3BnltfXy89k+LfIEVEGmiQIiINNEgRkQYapIhIAw1SRKSBBiki0kCDFBFpoEGKiDTQIEVEGmiQIiLvmsUmA5zmf8fUk3smD5tmsbmSlUwvOeOpNJGBJctcyWJTzz+n0kQmmT6nz3A1KTnYNB8+5J7TXPUPc8+VLDb1lXx4NUc/5J7TZ9BC/jfNh5PFZu6qOXr0VLLYjGmaD2dM2UcVhnFNNW1vb88yz5UsNjnp9G75MXuC96Pr7du33Y9mkNxZfe/evfjFGFilnoXAncTpwGNELJwHDx5MpolFU7kXm43Pov7ss8/iNjC7iiY2/cOHD0v3YmPY9CN9P4Za0cTG/PTTT+NFzWJm4zx9+jTWRH1F01CfGuRgQpV7sdn0FU3DuKZmhFHwg4E7n9M+8+6KJtbfJ598Etd//fXX3Zs3b+J7sekz66KqqVLPXnj16tUk92LHBslCq7g6hjemPn2G+rFtXCZNY8c1fYa6yzhOmF5aT+1YTalBUo+5pG1QO3auU4McM3eXbZ/Oz8+XNU29Jyr4N0gRkQYapIhIAw1SRKSBBiki0kCDFBFpoEGKiDTQIEVEGmiQIiINNEgRkXdN0hCjI/M4VT1ZWP6L+DTHTB3Z7Sk18X6iVWk+nNxztQ2eqWoiqpemBqgnYpn2gdTKmLlGU5rFJv5IVK+SpBm7/tIkDZpIuKQpFxIiY+e6ksUmRpfevc2YXsQ+XVxcnH0ShnMAptwTQ6a/ci7DezdIFkQ6KGPrmeD0Geoq9WM0De9PNxn1VU0XUX9R41TZyBVNvHfsOFXmDtI2quv1h5pSg6Se2rSNi1x/ixPu06k1VYjfSDj9yZMn8Yv5BqjU8yuHAzHSwyr4lmHxTKmJAzE4UCE9rIJfa/wqmlIT38ZoSg+rQDv9qLTBr8FKPd/gaKrkw1nMaRsYJL+mKpqG+tQghxNtKodVMN9jxrVyAhDz/OLFi6iWMWVfTDnXCwsLs0Mh0sMq+FXHZ8o9wa9UDvSY4rAK/wYpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpIvKuSRrSDGmUbEw90S0+6TPD+y+TpqF2yj5cRk3VZ6r11T4Mz/CpZKupnXqchlv+LsNc/1BTOk5z39dfxDhV5q6iaRKDrF4mX63nXmKiW+mhCkQTid3xz6k0Xbt2bRbTS2N9HKBBPZ8U7j6uaKKe6FYa60ML9YxtAotsuEw+hXpibmk/mDcia8QBK5oqET3qeS7tB3FJ3k/0LoENyVxUGPpQOayCMR3u7P5LMKZ7e3slo6hq2t7ensVX00gw64Lo4JB1n2JP8H50vX37tnvv9CHn5+eMYPyp1h8fH/erq6tx/dra2uyZKTXdvHmzX1lZies3Njb6o6OjSTXdvn27X1paius3Nzf7g4ODUhtnZ2el+jt37vSLi4tx/c7OTr+/vx/Xz83N9aenpyVNJycn/fz8fFy/t7fX7+7uxvULCwuzNqrjSl/SesZoe3s7rmcOmIsp5/rw8LC/evVqXL+8vDxbs1PuCfbc+vp66ZkU/wYpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRuexZbDKkZE/TK1bHZLFv3Ljxvy8ZT9ja2uo++OCDUu6ZNl6/fh23Qc727OwsrifbSp9TTVwDyrWYlSz2wcFBKYtN/ZRZbHLP1Sw2mioHQwxZ7PTC+ovMYrM3pspiM06XLYt9/fuzAFJN7CHamCKLHRsk9x5//PHH8YvZlJV6DoTgTuI3b97EG5+BuX//ftwGRvSLX/yimwr6fH5+XloMVT755JPu17/+dXyoBybPIRqPHj2K6tlc6K/MHc/cu3cvNm0Wc+Ve7OGkloomnrl7925s2oMJcTd7wjDHFU08g6bUtDEK5jm9F5v1R38rmpgH6lMzOjw8nO3RV69eRfUclMLept8p9OMPf/hDXI9ho6fyw+S9GySTWvlVMaaeya1c9F5to/IL5LJCHyrjNNROPXeVZ6r19Pki1tPQTsJwUlB1/aEpXYfVuRvePWacLtM+/W7iua7g3yBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRN41SUOWN82Ejqknd0oKIM1TEp/jmUobxJ4qVDKq8O38t92r66+6+YX8e2f9+Xq3+OfFUoSOPqd3dTMPlew2CZHq3JFjJvaZJjKYN2J3afKBPtNGVRP1aRtkjJnrNMeM/qqmYVwruWfmOY2uEhscs0+5/z3VtLW1NdtH6V4iNjh2nFLQxBjhCe+bfGeOiOqNqa88U62vQsbzN7/5TX6Axocr3d/9u7/r5tdzg/z7//D33c7D7ICEMf0eaqecu6G2oqlaP2Zt/C1qqtT/8Lmf+jj1E3lBbJAEwTlMIoVvpUo9h088f/48PiWEer7tK22kBzwMMOAcXpAa5OrGavfd3HezXzxZA/y/2qTyi4g+p78g+eXIKUOVceLXYKWeXzrUp79SGVd+7aRtMM9DGykciMHcVbLV6ErbGE4jqmjiVxGa0o1MG8xzeljF8AtyjKaU5eXl7quvvuq+/PLLuL66/vCOiiZ+Ob58+XKm633j3yBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRN41SUM6pHKdabWe2uGT1lfbqNwX/H/rimrnF7r5b+Znn1hTX9M0XMuaJkSq48T7x851mhCh/qI0VbLV6J9y/VXHaZjni9BUrV/4CWuaxCCJ/6TxtjH1RJ6ID6ZxQA5g4AJ6wvApRJ4qMOA3b97MD4bY3uhu//vb3Z/+nPVhrpvrljaXum6ppunWrVtxrI8+E/dibCNNc3OzuUvfD/v7+7NFmh5WwbzRD2JxqSbaqFxPSj2kXyQcqIBxER9MoL+0UblqlHGtXPuKFuqJWSYwppXDMMZo2t7enkVv00gw8Udin5UfJ1Xv4P0cWJEedDOJQT5+/Lj7/e9/H7+YyarUM+jkLytZbDLD9+/fj9s4PT0tnRIyXMKeZrHR8+KfXsSXqsONX97out24fGZcXKqeLiA2GSb56NGjuA0Wc2Xu2Fz37t2LTZUFzcZ58uRJrAcqmoC5Sw1sMJZKFpt3VzRhqtSnZoQBV7PYw/qoaPrd734X1x8eHpaz2Oyfu3fvTuYdR0dHZrF/Spx1XXfs4Ir85CkddyYZ/7Lrun/ddd3/7LruN13X/VPXddnvYhG5TGiQE7HVdd2/6rruX3Rdd/d7o/wfXdc95e9iP7Y4EYnQICeEv5wtf/+v3Hz+bdd1/63ruv/SdR1/9cn/DC0iPwb+meyCjJIP/1vMr7qu+zf8Af7HFiUifxF/QU5M//2Hf7X+713X/Wf+11V/PYr8JNAgJ4T/OIj/WOG/dl33j13XPf/eLEXkp4EGOQH8F2L/6fu/Nf7W/wVb5CeLBjkB/5ELwvxfq0V+8miQE/D+A08icqkN8uDgoJTxrNYT0yNPmWaxiTCR6a3kq6mvQM77l7/8ZSljXMluQ5qR/mGc7OTkJNbE+NCPNGM8zF0FInG0kcb66DNxsjRjTNTw+vXrpTwv9ZWDIciFU5tGUYnokRmOr/j9flyH62XTfDjzPOTKE03orxzaUJ3rra2tWXQwzT2jhWhp5cyEqnewjvCPNBI8WRa7ktmsZjyPj49nOdg3b95MlsXGWHimYkY///nP43oWAZM7xakiA2RtyRinXyQsaO4NTrPYbGA+lbnDGKfMYrOW2DAVTdST/02/SAZjTO9jZo55dyUzPGTc0y8STJ55TrPYrL9qFnvQlBrS4eHhbI+m5w2MyWJXvYMsNnpev37d/WgGyQBWXH1MPQsnfWZ4f7WNvwYq4zTUTj2uU7ZR7cNFrKex4zTl3L3LOFXr+wtYT1NpquB/KC4i0kCDFBFpoEGKiDTQIEVEGmiQIiINNEgRkQYapIhIAw1SRKSBBiki8q5JGnKhaSYUyP5W6slTEntKM57E52ijkr8k9lS5W7mSmx0iUsSdKpnhahvkvIfrQNOMMXeIp2kJ9FTnbqhPo4bUVy+GH6OJqF4636w/5iHVRV1VE3sITelcEItlntMcM/HNseOUrsGdnZ3Z3uOTgHbirmPGqXJXN+1UzzV4rwbJQqscwsBmGVOfPsNiqGr69NNPu3/4h38oZTzJ5qYmzGEVfNKMMdy6dav75JNP4vobN26Uxok6NnNaj0FW5455IDOcmhHvZvGnbWCQ1bkeNKVmNLw7bYP3jtWUbnzeXZkL3jtm7ob5mEITjF1PU3nHJAZJQD0NzY+p55cOl3//8Y/Z8bIMIBt/Sk18u1KfGiQTxUJ7/pyzwzP4Zq3U822MpspGrlw+D5xSU6nnlw5zl/6CxIT5gkvboJ42Kpo4fIL61CCHk3/SNobTiCqamGvqUzPiV1Fl7oZfkBVNX331VWn9XblyZfbMl19yLHR+6taU+5Rfjqw/dL1v/BukiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiMi7JmlIDvBf6k9VT+3wSeun1jTUpxG6i9SUpjGqmkitXEQfKs8QNRzTBkmUytwxpmkb1T4M/ajcH17VNHb9oSldTwvfv/8y7dOqd1SI30jU6+bNm91U9UTDiDGlGUwiTMQTK4ceVDURuaOdNNaH/tXV1dIl6WM0DdnkBPTQh/RwgbFzV7k+lOgZ85YeLoBp00Yla0s9Y5RufNbSD//5l2AOaCONVw6ahjhqArFB6vlnAmM69Lsy15Xc8/b29ix6m0aCMS0OuKgcyFJdf7yfNVU5uOa9GyQHMFQuJGdgKvVMEgdDpAPP5mIg79+/P5kmFuejR4/igWdzsZgfPnw4mSZM6MGDB7FZoAeTpB8pbLSKJrh3715sFixo+p0e6oFB8qloov7jjz+OTXsw+S+++KKU3a5oGsY1NYvh1KZKFhtzHKMp5fDwsJzFZm/fvXt3sj3BoTJmsUVELhgNUkSkgQYpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZEGGqSISAMNUkTkXaOGBwcHpTxltZ7YIFeaprnQlZWVWf6SGN1UmoifER+sZLH5oCuNw1U1ET+jz2msb8hip3neQVMFLnmnjTQDPGSxyfWmmmiDf6bQByJradRwyGAz52kWe8jFVzTRh0oWmzFNI3SMKfuocj4B0cGKpu0RWWyeqZxPUN0TRFeZt7dv33bvnT7k/PwcxfHnZz/7Wan+ww8/7NfW1uJ6ao+Pj0ttVPtw69at/sqVK3H91atX+6Ojo7h+bm6urOmjjz7ql5eX4/qtra3+8PBwUk0nJyf94uJiXL+zs9Pv7+/H9fPz8/3Z2VlJ0+npab+wsBDXX7t2rd/b24vreTdtVDTRB/qS1l+/fn02Vmn90tJSf+fOnZIm5po5T+s/+OCDfnNzM65nrd6+fXtSTTdu3Og3NjZKbaRM9q/YlW+Aob76zNRUNY3p80VomrJ+eGZKxmq6jP2eeu7G6Jl6nMZwWTT5N0gRkQYapIhIAw1SRKSBBiki0kCDFBFpoEGKiDTQIEVEGmiQIiINNEgRkXfNYpOTJrc5Vf2QIU2vWCXzfPXq1dK9xFVNZDwhzYeTeyZnnOZ/x2qiz2m/0UNuPc0xU1fVNORz0yw288Zcp5lhNNFGVRP16VzQZ9IYZMoTyGBXNQ3jmqY+mGvOAUjvNB/y7dVx+uCDD2JNu7u7szWVnjdABnvsOKWgiTWe5sMnMUhMonLvbLWeoDkdTDvJwmcxp22wyaqa2PRv3rwpXUjOIq1o4t1jNKUHaLCRWfwXMU6paXOAAZ+0DfowdpxS0x6MsXIwxFhNqWljjIxp2gZjOkYT9alBrq+vz/Zo2gbjykEgY8Yp1cT7K5omMUgEpJeFj6nnW4P61CBZ+Az+lJqYJOpTg2RC2cyVNvhiGKMpNUgMj7GacpyG+qpBpm3QhzGaXr16FZsRa4n5S9vAIKuamGs0pRsfg2Se0zYY07HjlLK+vj4zorQNxpV/YxgzTinD+6cwSP8GKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLyrkka/iv9NKc6pp7MZuVuZeovSlOafLhITWm2mvrhmQTeO6YPtJHeEV0dp7GaqE+TNGiqZLFJ0lQ18Ux1PUHaxpBQuoj1txw+c5F7Ik2XTWKQBM6Pjo66qeoJnNPR9GAIwunDZe9TamLTpwNPNIwDKyqXyVc1cYABmz79IllbW5stHhbdlJqIGaZmRFxtMIvUIGmjqol5SzURV8O4mL8E5pg2Kjn9oT41SOK3jGt6MARjShvpHhq7rzc2NmbjlcC6G9bHlPuUeSOi+L6Jd83Tp0+7u3fvxi9m8VfqGcBnz57FWWw2PgNz//79yTSxuR49ehRvAhbO5uZm9/Dhw8k0wYMHD2LTRg+Lh36k8EVV0YRZ3Lt3L94EbBg2zpMnT2KDZPNXNA31qUHu7e3NjOuLL76I34+uiqZhXFOD3N/fn83zixcvonrGlHeP0ZRyeHhYzmKzLqb0Dr4QXr58aRZbROQi0SBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRN41ali5yHtMPbFBMphpjpQ4EhlVIodTaSJ+RuY0jfWRDyfWV8mIHxwclDRdu3Zt1kaaxaaWOBm53oqm9DCMIRJXORiCORtywwlooY1Kxv369euzfqeamDNieoxvAlqopR+VcR3uKU9g7THPXPWbgBb2USV3X53rra2tWfQ2zT2jhX1dOXyiuid4P3u1kouP6UPOz8+Z1fhTrT8+Pu5XV1fj+rW1tdkzU2q6detWv7KyEtdvbGz0R0dHk2r66KOP+qWlpbh+c3OzPzg4iOvn5ub6s7OzkqY7d+70i4uLcf3Ozk6/v78f18/Pz/enp6clTdTzXFq/t7c3+6T1CwsL/cnJSUkT48r4pvXXr1/vt7e343rmgLmYUtPh4eFsTaX1y8vL/e3btyfdE+y59fX10jMp/iv2/4f0m/6vSdNfS58v6pkpuSg91Xb6SzZOU6JBiog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiohc9nuxyVKSnU3zlNxBTVY1zdqO1UR2Ns2Hk3uuZMPHaCJrS5/TK1bJq5ODTTPD73IHdZoPZ97Qw3xX7qCujhNrKV0fZIxJiLCuptI0zHWaRKGeeU7X1HAHdXXubty4EWva3d0t3YvNHPPMlHd1D+cTpFdGT2KQNM7dsxVzqdSzkblrN+0kA84inVITC+HVq1exabOYWWhpG5hRdVy55xpN6QEaGASbvqKJTVPRxIJGU+VyeDZz2gbzTBsVTfQBTalpY9iVuaMeU61owijQlJo25sI8p20wpuyjMXsiNciVlZXZmq3ci415TblPeT96prgXOzZITKIioFrPoFOfGuTwbT+lJk4soT41SMyFRXoRmlKDHDb+RWhKDZJNUxknxnVoo6Lp9evXsRmxlirjxLhWNTGuaErNiF+OzHPaBmM6Zu7QVN2nX4VtoH/MOI3xjikM0r9Biog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRBrMcfdr6/9TRORvGX9Biog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBioh0/2/+F0iFGC1KH7bmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env, obs = create_multiroom_env(1, 4)\n",
    "img_rgb = show_full_frame_rgb(env, obs)\n",
    "img_grey = show_partial_greyscale(env, obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22532\\4067957708.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  return torch.tensor(self.frames)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725,\n",
       "          0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725],\n",
       "         [0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725,\n",
       "          0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725],\n",
       "         [0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206,\n",
       "          0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206],\n",
       "         [0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980,\n",
       "          0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980],\n",
       "         [0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206, 0.3647, 0.3441,\n",
       "          0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206],\n",
       "         [0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980, 0.3941, 0.3716,\n",
       "          0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980]],\n",
       "\n",
       "        [[0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725,\n",
       "          0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725],\n",
       "         [0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725,\n",
       "          0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725],\n",
       "         [0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206,\n",
       "          0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206],\n",
       "         [0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980,\n",
       "          0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980],\n",
       "         [0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206, 0.3647, 0.3441,\n",
       "          0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206],\n",
       "         [0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980, 0.3941, 0.3716,\n",
       "          0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980]],\n",
       "\n",
       "        [[0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324,\n",
       "          0.0620, 0.0324, 0.0620, 0.0324, 0.0620, 0.0324],\n",
       "         [0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000,\n",
       "          0.0324, 0.0000, 0.0324, 0.0000, 0.0324, 0.0000],\n",
       "         [0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725,\n",
       "          0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725],\n",
       "         [0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725,\n",
       "          0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725],\n",
       "         [0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206,\n",
       "          0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206],\n",
       "         [0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980,\n",
       "          0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980],\n",
       "         [0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206, 0.3647, 0.3441,\n",
       "          0.3412, 0.3206, 0.3412, 0.3206, 0.3412, 0.3206],\n",
       "         [0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980, 0.3941, 0.3716,\n",
       "          0.3206, 0.2980, 0.3206, 0.2980, 0.3206, 0.2980]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class FrameStackPreprocess:\n",
    "    \"\"\"\n",
    "    A wrapper for preprocessing and stacking consecutive frames into different channels.\n",
    "    - Converts RGB frames to grayscale.\n",
    "    - Normalizes pixel values.\n",
    "    - Optionally downsamples to a target size.\n",
    "    - Stacks the last N frames to capture temporal information.\n",
    "\n",
    "    Parameters:\n",
    "        num_frames (int): Number of frames to stack.\n",
    "        img_size (tuple): Original (Height, Width) of frames.\n",
    "        downsample_size (tuple): Target (Height, Width) after downsampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_frames=3, img_size=(56, 56), downsample_size=(14, 14)):\n",
    "        self.num_frames = num_frames\n",
    "        self.frames = deque(maxlen=num_frames)  # Store last N frames\n",
    "        self.img_size = img_size  # Ensure all frames have the same shape\n",
    "        self.downsample_size = downsample_size  # Target downsampling resolution\n",
    "\n",
    "    def _convert_to_grayscale(self, frame):\n",
    "        \"\"\"Converts an RGB frame to grayscale and normalizes it.\"\"\"\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
    "        frame_gray = frame_gray.astype(np.float32) / 255.0  # Normalize pixel values\n",
    "        return frame_gray  # Shape: (H, W)\n",
    "\n",
    "    def _downsample(self, frame):\n",
    "        \"\"\"Resizes the frame to the target downsampling size.\"\"\"\n",
    "        return cv2.resize(frame, self.downsample_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def preprocess(self, frame):\n",
    "        \"\"\"Applies grayscale conversion and downsampling.\"\"\"\n",
    "        gray_frame = self._convert_to_grayscale(frame)\n",
    "        return self._downsample(gray_frame)\n",
    "\n",
    "    def reset(self, first_frame):\n",
    "        \"\"\"Initialize the frame stack with copies of the first preprocessed frame.\"\"\"\n",
    "        processed_frame = self.preprocess(first_frame)\n",
    "        for _ in range(self.num_frames):\n",
    "            self.frames.append(processed_frame)\n",
    "        return np.stack(self.frames, axis=0)  # Shape: (num_frames, H, W)\n",
    "\n",
    "    def update(self, new_frame):\n",
    "        \"\"\"Add a new frame to the stack and remove the oldest.\"\"\"\n",
    "        processed_frame = self.preprocess(new_frame)\n",
    "        self.frames.append(processed_frame)\n",
    "        return np.stack(self.frames, axis=0)  # Shape: (num_frames, H, W)\n",
    "    \n",
    "    def get_stack(self):\n",
    "      return torch.tensor(self.frames)\n",
    "\n",
    "\n",
    "env, obs = create_multiroom_env(1, 50)\n",
    "frame_stack=FrameStackPreprocess()\n",
    "frame_stack.reset(obs)\n",
    "frame_stack.get_stack()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"MiniGrid-MultiRoom-N6-v0\", render_mode=render_mode, highlight=highlight)\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "env = ImgObsWrapper(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that this fundemental class has no bug and doesn't miss crucial information for learning, we will explicitly check how the stack looks in every state in this simple environment when acting |allways forward\" with 1 big room with the reward in the other side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJoBJREFUeJztncmOXdmZnU80jGD0HaPJyBAZGUFSNuCBlSlAQw08k2EbHvkt/Aye+0n8ErZhwIYKHhiGJxKyoyiSyb5NMikpk9f4LvIYNEq7av2HPEEq+X3ARQJV/zl77W7dS4pr75nJZDLpRETk7zH79/9PIiICGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZEG813Ir3/96+727dtpeXdwcFCq397e7r799tvuz3/+c1S/sLDQraysdI8ePRpN087OTvf06dPuL3/5S1R//vz56efx48dxG/v7+92dO3fi+gsXLkz7/MMPP0T1S0tL3blz56b9SJiZmen29vZKmnZ3d7sHDx50r169iuqZt9nZ2e7Zs2ejaaL+/v37sabV1dXpf1mDCehnLu7evVuaa+rT8Nra2tp0nl+8eBHVz83NTffRvXv3Spoq47qxsTHdo999911UPz8/321ubk7nYqx9yvvR86c//Sl+5ve//31WOAm5evUqsxp/qvVHR0eTpaWluH55eXn6zJiaLl68OFlcXIzrV1dXJ4eHh6NqOj4+npw7dy6uX19fn+zv75fauHLlSqn+5ORkMj8/H9dvbW1Ndnd34/qZmZnJ5cuXS5pOT08ns7Ozcf3Ozs5ke3s7rp+bm5u2UR1X+pLWM0abm5txPXPAXIw51wcHB5O1tbW4fmFhYbpmx9wT7LmVlZXSMyn+EVtEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLyplls8pEVqvVkSMlUVrPYy8vLo2kii00etprF7nO9Y2gi/0ufv//++ziLzViRoa3knvlvJYu9uLgY58P7LPbW1lZJE8+kUE8GvZrFZnwrWWzyz5XcM8+lWez19fXpPFez2OSfx9K0MTCLzRoca0/wfvZqJYsdYxa7/TGLnX3MYufjaha7+0c/ZrFFRP4G0CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRBrEoU0ynkdHR91Y9X2eN81TVjPPQzSRtSVLmubDyT2Tk04zw2SMh2iCNItN7pkcLLnksTSRgyWHnWaxybczRsx3ArVDNJGhT7PY5J4hzfaTe67mf/s+pLlnMsbMc7rOWatoStdrr+lnP/tZrGl7e7t7+fJlnO1n3fFMul77NqpzzTpP8+GjGCQXqnM5fAqTW6lnszx69CjuJGbEpI6piTYePnwYbwImiYVQaYOFVqmnDTSlB2iwWfgySdvAIDGLiiY2MJrSTYCRYjBpGxgkbVQ00Qc0pabNWuLDGkxAP2ZanWs0pabNXDDPT548iQ2yMte9JupTg5ybm5vu0WfPnkX1/ZfzmPuU96Pn+fPn3TszyMoJHkPqMSHq02dYPP0zY2tKDZLFw4I4C02pQbJ4GKsxNfX1qUGyidnMlbkeMk6cgpOaEb+KMIm0DeZ6yDihKTUjNDHPlZNzhmoaa5/+8MMP7513VPDvIEVEGmiQIiINNEgRkQYapIhIAw1SRKSBBiki0kCDFBFpoEGKiDTQIEVE3jRJQ0Kkcgd1tZ50BdG+9D5maoknjqmpf3969/FZakqTNGhibNM2GP8hmmgnjfX1SZqKpuq49vVpkgZN1Sz20LlOkzT9OKXZamqHrqeU8+fPT8c0nWuSXGPvCTQxRum4jmKQZIAJkY9VT9aWDqaxPgadQw8qhwVUNfF+4nMVM+KT1g8dp62trTjWx0JjrNIF3bcxZK7TNng/BpMuaAxy6PqrHFaBnvQLmnz4UE1pv9HU59YTqBs6d5U9sbCwMP2kpn0WmpiP/kvunRgkIf4bN27EL2ZjVuqBgHqap+T9mOOYmhj0O3fuxCbMQmBR37p1azRNLLibN2/GJoweTJt+pFBf0cRmQVNq2hg8/bh3717pF2RFU1+fGiQnwmBcHCaRmhG/jiqa+nFNDZJ1xzw/fvw4qmdM0TVEU8r3338/PRSiclgFjLlPmWMO9BjjsAr/DlJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKf8fadROPlxmPqA1EkcNDw4OSi+u1pO95D7cNJhPhInMZiXUXtVE/IycZxrrIwvKJ73ofYimCxculA6GoJZIXHrRO4t/b2+vtAl2d3dLeW/mjRgnkcOKJp5JoZ5+p1HDfs4Y3wS0UJvmpGF/f3/6XBo1ZO0xpum1rGhhHxE5rGiqzPXGxkbpWla0sK/T7PaQPcH72auVcxliJiFXr15lVuNPtf7o6GiytLQU1y8vL0+fGVPTxYsXJ4uLi3H96urq5PDwcFRNx8fHk3PnzsX16+vrk/39/VIbV65cKdWfnJxM5ufn4/qtra3J7u5uXD8zMzO5fPlySdPp6elkdnY2rt/Z2Zlsb2/H9XNzc9M2quNKX9J6xmhzczOuZw6YizHn+uDgYLK2thbXLywsTNfsmHuCPbeyslJ6JsU/YouINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaxKFNso6XLl3qxqwnN5xmscn+9vcrj6WJjDEZ0koWu88+j6mJPG+aeyarTh8qdwajKZ0HIJNMvjjNPZPFZt7SHD1ZYdqo3DdOPWNUyT2//t80i51edduPK31INZF75v1pjp4x7fudQn1lrjc3N6eZ50oWu3IX+JA9wfuZt5cvX3bvzCCfPn3a3b59O34x5lWpZ3K5k7hyLzaLbUxNGN3du3dL92JX28AsKvWYHZoq92JjjjyTmlFVU//+1CzYZGyc+/fvx2bEF09FE/VoSs2iN4nKvdh8SVc0sWa5nzz9ImE8mWfufE5gTFmz1fWHptTAJpPJ9PCMyr3YzN+Y+5Q1iz+NcS92bJBMVOW0jGo9C5T69BkW6PumicXJpqm0wSYY0ofUIKllgY45Tn19apCMKyaRtsEGGKKJXxSpGaGJzT/m+mN80JSaEZoqbfBlMHScxtoTk8nkvdunFfw7SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRN03SVO97rtYTDeszumk9n7E1UZ9mq9Ff1dRnyqua0iQNmir9JrUyZK5pp5IPZ57TNkgCDV1/aZIGTaQ+0lwy+qua+rlOkzR9nDZNKBE1HDJO5JhTTUtLS9P/pvXsnaHjlIImxqhyv/coBkmud6x6FgOdTC8YZxAZmDE19WZEW2k9/ai2Ua1nQaebBj3oH3ucqE8Nsv8iTPvAwh8yTtRXDtCoHLjR58OHaErNBU2VwzAY0yF7Ij2g4/W5o/+paQ8dp5T+y4223jbxGx8/ftzdunUrfjHGUqlnwB88eFA+rGJMTQw4Qf7KYRVM7Jia+AL55ptvSodVsODoR2UTVDSxydCUbuatra3p2N67d69kkBVNfX1qeMwxm6x6WEVFUz+uqUEyx3zYe5XDKoZoSnn16tX0UIjqYRVj7gngQI8xDqvw7yBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRN53gxwjR/lT1VTRVe3D+9rnIc/8rff9LPT8FMZpTE1x1HB/f7/04oODg1I9l39zQXp6WAARJmJS6eXzQzRxgXklD9vnwytB++q4ctE70b4094we4mfp5fO9psqC293dnc5H5WAIonpEDhPQQhtp/hf29vambaSxvv4QCeY8AS3MRXq4Sj+uPJdqIiPNPHMPdQJa2EeVTHJ1/W1sbExjmelVsWjhHvT0jIUhmng/EeUxrn1lsiKuXr3KrMafav3R0dFkaWkprl9eXp4+M6amixcvThYXF+P61dXVyeHh4aiajo+PJ+fOnYvr19fXJ/v7+6U2rly5Uqo/OTmZzM/Px/VbW1uT3d3duH5mZmZy+fLlkqbT09PJ7OxsXL+zszPZ3t6O6+fm5qZtVMeVvqT1jNHm5mZczxwwF2PO9cHBwWRtbS2uX1hYmK7ZMfcEe25lZaX0TMp780dsEZH3DQ1SRKSBBiki0kCDFBFpoEGKiDTQIEVEGmiQIiINNEgRkQYapIhIAw1SRKRBHNokd5rmpIfWk3tO85T95eKV3GlVE/lf2kmvWCX3zCfNnZIxrmoiY0yfK/dio6e/8D3RRL/TPveaeC7NhzNv5IaZ7wTyy2iq3BFNfeWe6/6+6vQ+5l5T2mdgrulDmsUm90w9WeMExpQ20j5DP66ppq2trekeTfPhnAOQZu576APrL9VE/px5S/PhFWJ3efToUXfz5s34xWzMSj1wJ3HlXmwGvtIGJlGpZxPcvXu3dC82BwxwR3QCpsLBExVNmCN3BlfuxaYN+jGWJgwYTamBseHpx/379+N5oI2Kpv7O6tTA2FzVe7HZ/BVNjGvlrm6+OKv3YjNWQ/ZEakbff//91Bwr92LT36qmGzduxPW8/+nTp6Pcix0bJAut8quCgRxSnz5DXbWNoX34W9fExjmLuUsNsq9L28C0h2jCYFIz6n+xpG3w3iFzjabUjPp5TtvgvUPWU+VPMN8X11//J4v3aU9U8O8gRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUTeNElD/CfNqQ6pJ5fLv+gnvpW+n7hhpQ1qyZ6mEGUkMZFGDekDn8q/6Cd2V9XUR9ASiD4Su0sTJSQfqppog7FNkzR9FjsdV+Jz1bmmnixzJR9OEiXtA/qrmlizaErnAk3Mc1pPYmrIPkVTmu5ZWVmZzkd6bzr7ecg4Vb2DMarcUf7WDZKOpgceQOWAhL6erGo68NT+6le/Kg3KyclJfEACoCVdOEOfGbv+LNogU3379u34mX6OK22wKT/99NO4njY+++yzUn1V05dffhln3Ps9xLpN2+CLjfWdfhlSO2TfUV/RNPkx0pj2uappiNdUxnUUgyQMfufOnfjFfCtV6hmUBw8elA6rgMppPv0BA/J2wbzG+Pb+a+28T3A4QmWN86uI+nQj86uoelgFRlHVxJdb5Yvk+fPnpcMq0DWmd7D2njx5MsphFe/XihMReY/QIEVEGmiQIiINNEgRkQYapIhIAw1SRKSBBiki0kCDFBFpoEGKiLypQaYRwDeprzxTfb/I22bIGqyu8bH3xJA2Zs5gn46pqcJ85XL4yoXk1fr+8u/0CkoiTNV4G/f5prEtIA/KgQppP9BDrCo9hAHIhlciUmjq73Cu3JVcudqzqokY6u9+97t4nMjzoimNlbL4WRvEySpxNXSl48S4Hh8flzYaa/bKlStx/f7+finn3h8AcuHChXj9oamyL9AEqaaNjY3pWkrnjvXH4SeViC+aKrlqDnDhU9l3b90gyUZ+/vnn8YtZCJX6o6OjchabwwsqWWw2zNdffx3Xc6INhpoeFkAOFl3p5fNweHg4vUy+sng4HCI9LAA9fJlUvhiqmjDG3/72t/FJOCxm5u3evXvxWjo9Pe2++OKLWBP1zHVq2pjQpUuXSgbJeq2scaAP6eZn/VWz2BcvXuy++uqrkqZKHw4ODspZbNbTtWvXRvMO3m8WW0TkjNEgRUQaaJAiIg00SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaxDk9Yk9plGxI/c7OzvSi9DQz3Od5KxAFJCqVQhaWqFTlDmB08UxK5SL5vp6sbfpMf+0mfR9LE/HQTz75JB4nst70YW1tLY6eVbP9fe45fYa5rh54QGSSu9YrewI9lSw2Y0q+OoExZR9V6Mc11bS5uTnNPFey2IxTZa9WvYP3o4szCt6ZQZI7vX79evxijKJSz0Igw5wOPIcL/PKXv+wqMLGVi95ZNJUsNpr4pFlsNiQLqKIJeH+6gKpZ7CGa2GB//OMfY00sZtogU17RVFlPfX0li818V0yS/G9FE1+g1Fey2PxgSA/poM+8u6KJtfGHP/yhtIdevHgRZ7HpM+uiqqlSz/7knIUxstixQbLQKq6O4Q2pT59Jf628Dotn9tWraadfhn3uP6mmSv3rbVT60LdTef+Ymvq1UZk7jCitp3boekr7UXn30D3R16cGSW213+/bPp2dnR08TmNpqvDB/R3kx13X/Yeu6/4Vf7xg871rQSLy3pKfFfYTgZPy/knXdf+067p/23Xd33Vd91+7ruOAqOwP0iLyofDBGeTrP513u677l13X/Yuu637fdd1/7rruf3Vdl5+cKCI/ZT5Yg+zhj9hLXdf9867r/lnXdTe6rvtPXdf993ctTETeOR+8QQJ/Zf6i67r/03Xdf+m67n//+H8TkQ+bD9og+d/B73Rd9z+6rvtvXdf9kf/l8F2LEpH3hg/SIF/++D/K8Gvxf/Lv2fzFKCJ/hQ/OIO/9+M98MMj8nj8R+RD54AySf///u3ctQkR+WgZJfpbM41j15HL5F/FpZpi6anaWKBZ57xTaoB/pv9AnXskz1TaG1KdJIur7uFcK/ahoIg5HfDDVRMaY3HAlSTN0/Y2ZxSZWWtFE7JP6ShabGF2qizE9i306Pz8fX7fM2qu20Y9TRRNUzkB46wZJZKhyB/WQeiY4fYa66oKmvhKa7zWlm4z6/pPqqWrq69NNNkRTpb5vozIfjGllrnlvpb5vg/p07qivUl3jvaZ07qinNm2jOq6va6rWzxf26fumqUL8RsLp6UXvwDdApZ5fLRyIkR5WwbdMJS/8eqi9oon69LAKfq3xK6rSBt+ulXp+tVCf/lrjVxrfrGNqYh44eCL9RUgdizldHxgkv6Yq66mvT9cIRlQ9rILDESqa+JVNfWqQwNpLDxphTNkXQzRVzOj58+fxYRWsPT5jege/UjnQY4zDKj64LLaISIoGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJE5E2TNH0sbqz6Pt6WPlONGQ7R1NdXNI09Tq/fFPe+aBp7nPp1MWQ9VSKZVYaMU2XuqntiyDhVo6szP9aPvSeGxGmHeMJbM0guGK9ctVqt53J0Dkjg4IM0Blhd1EQBDw4OSnE12kkjdH2sqhKa39jYKEUmqSdalY4t+omgpYeAsMiqmoiHnpycxJqIMhJZY3xTTaynSkSPep5L+8GBB9UNRiTu9PS0pKmPNCYwPowpeyOBMd3Z2Sn1o6ppc3Nzejd2Gglm7TFOlaw794FXvIP3o+vly+Qy55EM8s6dO90XX3wRvxjzqtQfHR2Vs9iffvppV4F3f/PNN3E9xkgOtpLFRtfDhw/jNljMFU197jldQOjBsNM8b09V05dffhl/kbCgq1lsNnBlPVH/9ddfxwZ54cKF7he/+EXJXJjniibeTX1qRhhFNYtN/VdffVXS9Pnnn8f1BwcH5Sz24eFhd+3atdG8g/ebxRYROWM0SBGRBhqkiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGR9z2LTYaU7Ck5z7Gy2FyZ+tFHH8X15HNpJ+0HGWmiVTyTQoa0kjFmjCr3PaOHevo+lqZqFnv2cLa7+W9udl2WKp2y9Xdb3ekkzz3v7++XDoZgXKtZbDLSZ5HFZm+MlcVmnN63LPbe3t503lJNzANtvNMsNvlfsq0pmEWlngwp2dYXL17EGePPPvusq8AA3r59O65ncZLxTA/QwIT4pFns/tSSiiYWDZn1NPdczWIP0cRiJmubaupWu+7Vv3/VdefCBn7ousf/7nFpPdEHNKWmTe65msV+9OhRSRMmgabUtDEK1l46d/0hJhVNGBj1qRkdHBxM92h6bzprj71dyWLTj0qeHMNGz7ffftu9M4NkUisnvAypZ3LTZyrv7ql8U/b1lW+yvjat72vH1FRt4000xXNSn7r/18ZY66nyp52hmqinnXRse/2VPgwdpzH36av3zDsq+HeQIiINNEgRkQYapIhIAw1SRKSBBiki0kCDFBFpoEGKiDTQIEVEGmiQIiJvmqThzuo0EzqkntwpKYA0T8kVq9XsLP/SnhhTCu8nilWJkvFMpQ0YUp/m0NFEbaUN5qFSz7hybWocNVzpuo7kWTi0s69mu7W5tWkblfVUuV+ZLG91PRHjHLInKrlnYnppjpm1OmSfMq6ppo2NjdLd76wjzjQY0zvQxBild79XyHf/jxtn7PrqMxXIbKaXsPekl9u/TqUNzKWqiQUxpibmoKrpN7/5TV6MD/3H0uu7mfWZ7hf/+hd5/czMNFtdqa8yJJL5+n/fdf3rz42paXIG4zSWd8QGSRA8PYQB+Faq1PNtTPg/PSWE+iEDMmQjjM1PQVO5D9WpmzkDTUVYq5U1zq8iDhpJ1y2/ivgFmR5W0f+CHKIpZWFhoXv+/Hn37NmzuL5ygEvvHRVN/HLkUBl0vW38O0gRkQYapIhIAw1SRKSBBiki0kCDFBFpoEGKiDTQIEVEGmiQIiINNEgRkTdN0pDnrdxtW62ntv+k9SLvkqF7opKkIYpa2RNj79PZH+v/ljWNYpDEf4g9jVVP5In4YHoH9eLiYnf9+vU48tS3UYkwkXkmvpQewkCsCl1jauIAA96fHsKAHg4MSO8MJp5HDruiiYMeiHql124SPWNRp9EwNNFGJa5GH4iupmbUR1fTqCv6ibgdHx+X9kTl2lfOAaCeOU/AICqHYQzRtLm5OT3TIB0n4o/Vg0Cq3sH72avpQTclJiFXr15lBONPtf7o6GiytLQU1y8vL0+fGVPTxYsXJ4uLi3H96urq5PDwcFRNx8fHk3PnzsX16+vrk/39/VIbV65cKdWfnJxM5ufn4/qtra3J7u5uXD8zMzO5fPlySdPp6elkdnY2rt/Z2Zlsb2/H9XNzc9M2quNKX9J6xmhzczOuZw6YizHn+uDgYLK2thbXLywsTNfsmHuCPbeyslJ6JsW/gxQRaaBBiog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBioi8aRZ7f3+/lPGs1pOdJU+ZZrHJPa+srExzvWNpItdKG2kWm9wzenhmLE3kVMkAp1ls9JDFrtzvjaYKu7u70zbSLDa5Z3LDacaYHO/e3l4pz0t95WAIrkulNr2wniw2c8F/K+NKH1JNa2tr03lmfFNN6K8c2lCd642NjWkWO809o4WsNOtjrD3BOsI/0PXODPLu3bvdF198Eb+YyarUHx0dTQ8jePHiRbzJGJQbN26Mpgmzpt/pYmCTYUS3bt0aTRNmzfvTLxIWNIZ6586dqJ4NzKeiCWPk4JD0i4QNwyEG9+7di8eIDVPRRP21a9fiL5LeGNNDOtj4vPvLL7+MNTGu1KdfJJg885zei40JMQdfffVVWVNqSAcHB9M9+vTp0/iHDMbFXIy1Jw4PD6d60gNZRjFIBrDi6kPqWTjpM/371fQP09eeRR/GaqPah7OYu6HjNObcvck4fUh7ooJ/Byki0kCDFBFpoEGKiDTQIEVEGmiQIiINNEgRkQYapIhIAw1SRKSBBiki8qZJGnKhaSYUiNxV6slTEntKY33E52ijkr+s9oGYHnGyNNZH/JEcdnqnL/0dogk9aRvEH8mIp2kJNFXnrq9Po4bUVy+GH6KJqF4aNWT9kcRIdVFX1cRcoymdC6K0zHOaYya+OXSc0hTK1tbWdO/xSUA7a3bIOFXu6qYd9t87M0gWWuUybzbLkPr0GRZDVdPQ+vQZ6qr9HjquFU1s5oppD+kDpp2aEe9m8adtYJBD5g5NqRn1707b4L1DNaUbv7qeeO/Q9TeWJhi6nsbaE6MYJAH1NDQ/pJ5fOk+ePOm+++67qJ4BZOOPqYlvVzSlv1L7X1BjauLbkvrKRqa20gan1FTq+aXDOKW/IDFhvuDSNqinjYomDp+gPjXI/uSftI3+NKKKJn5FUZ+aEb+KKnPX/4KsaHr+/Hn36NGjuP78+fPTZ549e1Y6dWvMPcEvR9Yfut42/h2kiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiMibJmlIDvAv9ceqp7b/pPVja+rr0wjdWWpK0xhVTaRWzqIPlWeIGg5pgyRKZe4Y07SNah/6flTuD69qGrr+0JSup7kf3/8+7dOqd1SI30jU6+LFi91Y9UTDiDGlGUwiTMQTK4ceVDURuaOdNNaH/qWlpdIl6UM09dnkBPTQh/RwgaFzV7k+lOgZ85YeLoBp00Yla0s9Y5RufNbS6//9x2AOaCONV/aaqE81ERuknv8mMKZ9vytzXck9b25uTqO3aSQY0+KAi8qVrNX1x/tZU5WDa966QXLJe+VCcgamUs8kcWl7OvBsLgbyxo0bo2licd65cyceeDYXi/nWrVujacKEbt68GZsFejBJ+pHCRqtoguvXr8dmwYKm36yp1CD5VDRR//XXX8em3Zv8w4cPS9ntiqZ+XFOzILtdzWJjjkM0pRwcHJSz2Ozta9eujbYnDg8PzWKLiJw1GqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZEGGqSIyJtGDff390t5ymo9sUEuGE9zoYuLi9P8JTG6sTQRPyM+WMli80FXGoeraiJ+Rp/TWF+fxU7zvL2mClzyThtpBrjPYpPrTTXRBv9NoQ9E1tKoYZ/BZs7TLHafi69oog+VLDZjmkboGFP2UeV8AqKDFU2bA7LYPFM5n6C6J4iuMm8vX77s3jqTkKtXr6I4/vz85z8v1f/sZz+bLC8vx/XUHh0dldqo9uHSpUuT8+fPx/Vra2uTw8PDuH5mZqas6ZNPPpksLCzE9RsbG5ODg4NRNZ2enk7m5+fj+q2trcnu7m5cPzs7O7ly5UpJ0+XLlydzc3Nx/YULFyY7OztxPe+mjYom+kBf0vq9vb3pWKX1586dm5ycnJQ0MdfMeVr/0UcfTdbX1+N61urx8fGomj7++OPJ6upqqY2U0f6IXfkG6Ourz4xNVdOQPp+FpjHr+2fGZKim97HfY8/dED1jj9MQ3hdN/h2kiEgDDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiMibZrHJSZPbHKu+z5CmV6ySeV5bWyvdS1zVRMYT0nw4uWdyxmn+d6gm+pz2Gz3k1tMcM3VVTX0+N81iM2/MdZoZRhNtVDVRn84FfSaNQaY8gQx2VVM/rmnqg7nmHID0TvM+314dp48++ijWtL29PV1T6XkDZLCHjlMKmljjaT58FIPEJCr3zlbrCZrTwbSTLHwWc9oGm6yqiU3/4sWL0oXkLNKKJt49RFN6gAYbmcV/FuOUmjYHGPBJ26APQ8cpNe3eGCsHQwzVlJo2xsiYpm0wpkM0UZ8a5MrKynSPpm0wrhwEMmScUk28v6JpFINEQHpZ+JB6vjWoTw2Shc/gj6mJSaI+NUgmlM1caYMvhiGaUoPE8BirMcepr68aZNoGfRii6enTp7EZsZaYv7QNDLKqiblGU7rxMUjmOW2DMR06TikrKytTI0rbYFz5E8OQcUrp3z+GQfp3kCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRBpokCIib5qk4V/ppznVIfVkNit3K1N/VprS5MNZakqz1dT3zyTw3iF9oI30jujqOA3VRH2apEFTJYtNkqaqiWeq6wnSNvqE0lmsv4XwmbPcE2m6bBSDJHB+eHjYjVVP4JyOpgdDEE7vL3sfUxObPh14omEcWFG5TL6qiQMM2PTpF8ny8vJ08bDoxtREzDA1I+JqvVmkBkkbVU3MW6qJuBrGxfwlMMe0Ucnp9/WpQRK/ZVzTgyEYU9pI99DQfb26ujodrwTWXb8+xtynzBsRxbdNvGvu37/fXbt2LX4xi79SzwA+ePAgzmKz8RmYGzdujKaJzXXnzp14E7Bw1tfXu1u3bo2mCW7evBmbNnpYPPQjhS+qiibM4vr16/EmYMOwce7duxcbJJu/oqmvTw1yZ2dnalwPHz6M34+uiqZ+XFOD3N3dnc7z48ePo3rGlHcP0ZRycHBQzmKzLsb0Dr4Qnjx5YhZbROQs0SBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRN40ali5yHtIPbFBMphpjpQ4EhlVIodjaSJ+RuY0jfWRDyfWV8mI7+/vlzRduHBh2kaaxaaWOBm53oqm9DCMPhJXORiCOetzwwlooY1Kxn1vb2/a71QTc0ZMj/FNQAu19KMyrv095QmsPeaZq34T0MI+quTuq3O9sbExjd6muWe0sK8rh09U9wTvZ69WcvExk5CrV68yq/GnWn90dDRZWlqK65eXl6fPjKnp0qVLk8XFxbh+dXV1cnh4OKqmTz75ZHLu3Lm4fn19fbK/vx/Xz8zMTK5cuVLSdHJyMpmfn4/rt7a2Jru7u3H97Ozs5PLlyyVN1PNcWr+zszP9pPVzc3OT09PTkibGlfFN6/f29iabm5txPXPAXIyp6eDgYLqm0vqFhYXJ8fHxqHuCPbeyslJ6JsU/Yv8DpN/0PyVNP5U+n9UzY3JWeqrtTN6zcRoTDVJEpIEGKSLSQIMUEWmgQYqINNAgRUQaaJAiIg00SBGRBhqkiEgDDVJE5H2/F5ssJdnZNE/JHdRkVdOs7VBNZGfTfDi550o2fIgmsrb0Ob1ilbw6Odg0M/wmd1Cn+XDmDT3Md+UO6uo4sZbS9UHGmIQI62osTf1cp0kU6pnndE31d1BX5+7jjz+ONW1vb5fuxWaOeWbMu7r78wnSK6NHMUga5+7ZirlU6tnI3LWbdpIBZ5GOqYmF8PTp09i0WcwstLQNzKg6rtxzjab0AA0Mgk1f0cSmqWhiQaOpcjk8mzltg3mmjYom+oCm1LQx7MrcUY+pVjRhFGhKTRtzYZ7TNhhT9tGQPZEa5OLi4nTNVu7FxrzG3Ke8Hz1j3IsdGyQmURFQrWfQqU8Nsv+2H1MTJ5ZQnxok5sIiPQtNqUH2G/8sNKUGyaapjBPj2rdR0fTtt9/GZsRaqowT41rVxLiiKTUjfjkyz2kbjOmQuUNTdZ8+D9tA/5BxGuIdYxikfwcpItJAgxQRaaBBiog00CBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaTDD3a+t/6eIyIeMvyBFRBpokCIiDTRIEZEGGqSISAMNUkSkgQYpItJAgxQRaaBBiog00CBFRLq/zv8FqVbSIUE958gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[100, 100, 100],\n",
       "        [100, 100, 100],\n",
       "        [100, 100, 100],\n",
       "        ...,\n",
       "        [100, 100, 100],\n",
       "        [100, 100, 100],\n",
       "        [100, 100, 100]],\n",
       "\n",
       "       [[100, 100, 100],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[100, 100, 100],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[100, 100, 100],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[100, 100, 100],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[100, 100, 100],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], shape=(800, 800, 3), dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env, obs = create_multiroom_env(1, 50, seed=333)\n",
    "show_full_frame_rgb(env, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on the stack in the 7 first step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x1400 with 21 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_stack = FrameStackPreprocess()\n",
    "frame_stack.reset(obs)\n",
    "frame_stack.get_stack().shape\n",
    "\n",
    "action = 2 # Always move forward\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_frame_stack(env, preprocessor, policy, N=7):\n",
    "    \"\"\"\n",
    "    Runs N iterations, updates FrameStackPreprocess, and directly plots stack positions.\n",
    "\n",
    "    Parameters:\n",
    "        env: The MiniGrid environment (already initialized).\n",
    "        preprocessor: Instance of FrameStackPreprocess.\n",
    "        policy: Function that returns the action to take.\n",
    "        N: Number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        None (displays plots).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(N, 3, figsize=(9, 2 * N))  # N rows, 3 columns\n",
    "\n",
    "    for i in range(N):\n",
    "        action = policy(env)  # Get action from policy\n",
    "        obs, _, _, _, _ = env.step(action)  # Step in environment\n",
    "        stacked_frames = preprocessor.update(obs)  # Update the stack\n",
    "\n",
    "        for j in range(3):  # 3 stacked frames\n",
    "            axes[i, j].imshow(stacked_frames[j], cmap=\"gray\")\n",
    "            axes[i, j].axis(\"off\")\n",
    "            if i == 0:\n",
    "                axes[i, j].set_title(f\"Place {j+1} in Stack\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_frame_stack(env, frame_stack, lambda env: 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the stack work well, the transformation of the image still allows to distinct between the tiles of wall, open tile, doors and goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing DQN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNet Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Q-Network model for our RL task - the NN component for DQN, DDQN and Dueling DQN Agents.\n",
    "    \n",
    "    This network consists of:\n",
    "    - Convolutional layers for feature extraction.\n",
    "    - Fully connected layers for action selection.\n",
    "    \n",
    "    Args:\n",
    "        input_size (Tuple[int, int, int]): Tuple representing (channels, height, width) of input.\n",
    "        num_actions (int): Number of possible actions in the environment.\n",
    "\n",
    "    Example:\n",
    "        >>> model = DQN((4, 84, 84), num_actions=6)\n",
    "        >>> x = torch.randn(1, 4, 84, 84)  # Batch of one sample\n",
    "        >>> output = model(x)\n",
    "        >>> print(output.shape)  # Expected: (1, 6)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size: Tuple[int, int, int], num_actions: int) -> None:\n",
    "        super(QNet, self).__init__()\n",
    "\n",
    "        # Extract input dimensions\n",
    "        c, h, w = input_size  # (number of frames, height, width)\n",
    "\n",
    "        # Convolutional layers for feature extraction\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(c, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Compute the flattened size after convolutions\n",
    "        conv_out_size = self._get_conv_size((c, h, w))\n",
    "\n",
    "        # Fully connected layers for decision making\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_actions)\n",
    "        )\n",
    "\n",
    "    def _get_conv_size(self, shape: Tuple[int, int, int]) -> int:\n",
    "        \"\"\"\n",
    "        Computes the flattened size of the feature maps after convolutional layers.\n",
    "\n",
    "        Args:\n",
    "            shape (Tuple[int, int, int]): Input shape (channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            int: Number of elements after flattening.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            dummy_tensor = self.conv(torch.zeros(1, *shape))  # Pass a dummy tensor\n",
    "            return int(np.prod(dummy_tensor.view(-1).size()))  # Compute total elements\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output Q-values for each action, shape (batch_size, num_actions).\n",
    "        \"\"\"\n",
    "        x = self.conv(x)  # Apply convolutional layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)  # Apply fully connected layers\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Qnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 5])\n",
      "Output values: [[-0.05816913 -0.00492953 -0.09617288 -0.03217846  0.03530537]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define input size and action space\n",
    "input_size = (4, 10, 10)  # (channels, height, width) - example\n",
    "num_actions = 5  # Example number of actions\n",
    "\n",
    "# Initialize model\n",
    "model = QNet(input_size, num_actions)\n",
    "\n",
    "# Generate a test input (batch_size=1)\n",
    "test_input = torch.ones(1, *input_size)  # All ones, should produce deterministic output\n",
    "\n",
    "# Forward pass\n",
    "output = model(test_input)\n",
    "\n",
    "# Print output\n",
    "print(\"Output shape:\", output.shape)  # Should be (1, num_actions)\n",
    "print(\"Output values:\", output.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.0029878185596317053\n",
      "Iteration 10: Loss = 0.0004136487259529531\n",
      "Iteration 20: Loss = 0.0011386402184143662\n",
      "Iteration 30: Loss = 0.00015897904813755304\n",
      "Iteration 40: Loss = 6.421763828257099e-05\n",
      "Iteration 50: Loss = 2.3050328309182078e-05\n",
      "Iteration 60: Loss = 4.95348922413541e-06\n",
      "Iteration 70: Loss = 2.1119160464877496e-06\n",
      "Iteration 80: Loss = 1.2057687399646966e-06\n",
      "Iteration 90: Loss = 2.7837819516207674e-07\n",
      "Final loss: 5.837384264850698e-08\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Generate a single data point\n",
    "x = torch.ones(1, *input_size)  # Input\n",
    "y_target = torch.zeros(1, num_actions)  # Simple target\n",
    "\n",
    "# Training loop (few iterations)\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Iteration {i}: Loss = {loss.item()}\")\n",
    "\n",
    "# Final check: Should decrease if network works\n",
    "print(\"Final loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter conv.0.weight updated correctly.\n",
      "Parameter conv.0.bias updated correctly.\n",
      "Parameter conv.2.weight updated correctly.\n",
      "Parameter conv.2.bias updated correctly.\n",
      "Parameter fc.0.weight updated correctly.\n",
      "Parameter fc.0.bias updated correctly.\n",
      "Parameter fc.2.weight updated correctly.\n",
      "Parameter fc.2.bias updated correctly.\n"
     ]
    }
   ],
   "source": [
    "# Get initial parameters\n",
    "initial_weights = {name: param.clone() for name, param in model.named_parameters()}\n",
    "\n",
    "# Perform one training step\n",
    "optimizer.zero_grad()\n",
    "y_pred = model(x)\n",
    "loss = criterion(y_pred, y_target)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Check if any parameters changed\n",
    "for name, param in model.named_parameters():\n",
    "    if torch.equal(param, initial_weights[name]):\n",
    "        print(f\"Warning: {name} did not update!\")\n",
    "    else:\n",
    "        print(f\"Parameter {name} updated correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "from typing import Tuple, List, Deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A replay buffer for storing and sampling experiences for agents using Q nets.\n",
    "\n",
    "    This buffer:\n",
    "    - Stores experiences as (stacked_state, action, reward, stacked_next_state, done).\n",
    "    - Maintains a deque for storing the last `buffer_size` experiences.\n",
    "    - Samples complete frame stacks (not individual frames).\n",
    "    - Provides batch sampling for training deep Q-networks.\n",
    "\n",
    "    Args:\n",
    "        buffer_size (int): Maximum number of experiences to store.\n",
    "        batch_size (int): Number of samples to retrieve per batch.\n",
    "\n",
    "    Example Usage:\n",
    "        >>> buffer = ReplayBuffer(buffer_size=10000, batch_size=32)\n",
    "        >>> buffer.add(stacked_state, action, reward, stacked_next_state, done)\n",
    "        >>> batch = buffer.sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size: int, batch_size: int) -> None:\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.memory: Deque[Tuple[np.ndarray, int, float, np.ndarray, bool]] = deque(maxlen=buffer_size) # (state, action, reward, next_state, done)\n",
    "\n",
    "    def add(self, stacked_state: np.ndarray, action: int, reward: float, stacked_next_state: np.ndarray, done: bool) -> None:\n",
    "        \"\"\"\n",
    "        Adds a new experience to the replay buffer - Deque data structure dealls with deleting the old\n",
    "\n",
    "        Args:\n",
    "            stacked_state (np.ndarray): Stacked state of shape (num_frames, H, W).\n",
    "            action (int): Action taken.\n",
    "            reward (float): Reward received.\n",
    "            stacked_next_state (np.ndarray): Next stacked state of shape (num_frames, H, W).\n",
    "            done (bool): Whether the episode ended.\n",
    "        \"\"\"\n",
    "            # Debugging: Check input shapes before storing\n",
    "        if stacked_state.shape != (3, 14, 14):\n",
    "            # print(f\"❌ WARNING: Adding a state with shape {stacked_state.shape}. Expected (3, 14, 14).\")\n",
    "            pass\n",
    "\n",
    "        if stacked_next_state.shape != (3, 14, 14):\n",
    "            # print(f\"❌ WARNING: Adding a next_state with shape {stacked_next_state.shape}. Expected (3, 14, 14).\")\n",
    "            pass\n",
    "\n",
    "        # print(f\"✅ Adding experience at step {len(self.memory)}: state {stacked_state.shape}, next_state {stacked_next_state.shape}\")\n",
    "\n",
    "        self.memory.append((stacked_state, action, reward, stacked_next_state, done))\n",
    "\n",
    "    # def sample(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # \"\"\"\n",
    "        # Samples a batch of experiences from the replay buffer.\n",
    "\n",
    "        # Returns:\n",
    "        #     Tuple of Tensors:\n",
    "        #     - states (torch.Tensor): Tensor of shape (batch_size, num_frames, H, W)\n",
    "        #     - actions (torch.Tensor): Tensor of shape (batch_size,)\n",
    "        #     - rewards (torch.Tensor): Tensor of shape (batch_size,)\n",
    "        #     - next_states (torch.Tensor): Tensor of shape (batch_size, num_frames, H, W)\n",
    "        #     - dones (torch.Tensor): Tensor of shape (batch_size,)\n",
    "        # \"\"\"\n",
    "        # if len(self.memory) < self.batch_size:\n",
    "        #     raise ValueError(\"Not enough samples in the buffer to draw a batch.\")\n",
    "\n",
    "        # batch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        # states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        # # Ensure states are converted properly\n",
    "        # states = np.array(states, dtype=np.float32)  # Ensure consistent dtype\n",
    "        # next_states = np.array(next_states, dtype=np.float32)  # Ensure consistent dtype\n",
    "\n",
    "\n",
    "        # # Convert to PyTorch tensors\n",
    "        # states_tensor = torch.tensor(np.array(states), dtype=torch.float32)\n",
    "        # actions_tensor = torch.tensor(actions, dtype=torch.int64)\n",
    "        # rewards_tensor = torch.tensor(rewards, dtype=torch.float32)\n",
    "        # next_states_tensor = torch.tensor(np.array(next_states), dtype=torch.float32)\n",
    "        # dones_tensor = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "        # return states_tensor, actions_tensor, rewards_tensor, next_states_tensor, dones_tensor\n",
    "            # \"\"\" Samples a batch of experiences from the replay buffer \"\"\"\n",
    "    # def sample(self):\n",
    "    \n",
    "    def sample(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\" Samples a batch of experiences from the replay buffer \"\"\"\n",
    "        print(\"i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            raise ValueError(\"Not enough samples in the buffer to draw a batch.\")\n",
    "\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        \n",
    "        print(\"Sampled batch:\")\n",
    "        for i, experience in enumerate(batch):\n",
    "            # print(f\"Experience {i}: {[x.shape if hasattr(x, 'shape') else type(x) for x in experience]}\")\n",
    "            pass\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        try:\n",
    "            states_tensor = torch.tensor(np.array(states), dtype=torch.float32)\n",
    "            actions_tensor = torch.tensor(actions, dtype=torch.int64)\n",
    "            rewards_tensor = torch.tensor(rewards, dtype=torch.float32)\n",
    "            next_states_tensor = torch.tensor(np.array(next_states), dtype=torch.float32)\n",
    "            dones_tensor = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "            return states_tensor, actions_tensor, rewards_tensor, next_states_tensor, dones_tensor\n",
    "        except Exception as e:\n",
    "            print(\"Error during tensor conversion:\", e)\n",
    "            print(\"Problematic states shape:\", np.array(states, dtype=object).shape)\n",
    "            print(\"Problematic next_states shape:\", np.array(next_states, dtype=object).shape)\n",
    "            raise e\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the current size of the replay buffer.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of experiences stored.\n",
    "        \"\"\"\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ReplayBuffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Replay Buffer with sample experiences...\n",
      "Replay Buffer filled. Current size: 100\n",
      "\n",
      "Sampling from Replay Buffer...\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "\n",
      "Verifying sampled data...\n",
      "✔ Passed shape verification.\n",
      "✔ Passed value verification.\n",
      "✔ Passed state transition verification.\n",
      "\n",
      "🎉 Replay Buffer Verification Complete: All Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define buffer parameters\n",
    "buffer_size = 1000\n",
    "batch_size = 5\n",
    "num_frames = 3  # Stack 3 frames per state\n",
    "height, width = 56, 56  # Frame resolution\n",
    "\n",
    "# Initialize FrameStackPreprocess and ReplayBuffer\n",
    "frame_stack = FrameStackPreprocess(num_frames=num_frames, img_size=(height, width), downsample_size=(height, width))\n",
    "buffer = ReplayBuffer(buffer_size=buffer_size, batch_size=batch_size)\n",
    "\n",
    "# Create a dummy environment-like frame (random grayscale image)\n",
    "def generate_fake_frame():\n",
    "    return np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)  # Simulating an RGB frame\n",
    "\n",
    "# Fill the buffer with experiences\n",
    "print(\"Filling Replay Buffer with sample experiences...\")\n",
    "\n",
    "for i in range(100):  # Add 100 experiences\n",
    "    frame = generate_fake_frame()\n",
    "    if i == 0:\n",
    "        stacked_state = frame_stack.reset(frame)  # Initialize stacked frames\n",
    "    else:\n",
    "        stacked_state = frame_stack.update(frame)  # Update frame stack\n",
    "\n",
    "    action = np.random.randint(0, 5)  # Random action (5 actions)\n",
    "    reward = np.random.uniform(-1, 1)  # Random reward\n",
    "    done = np.random.choice([True, False], p=[0.1, 0.9])  # Random termination flag (10% chance)\n",
    "\n",
    "    # Generate the next state\n",
    "    next_frame = generate_fake_frame()\n",
    "    stacked_next_state = frame_stack.update(next_frame)\n",
    "\n",
    "    # Store experience\n",
    "    buffer.add(stacked_state, action, reward, stacked_next_state, done)\n",
    "\n",
    "# Check buffer length\n",
    "print(f\"Replay Buffer filled. Current size: {len(buffer)}\")\n",
    "\n",
    "# Sample a batch\n",
    "print(\"\\nSampling from Replay Buffer...\")\n",
    "states, actions, rewards, next_states, dones = buffer.sample()\n",
    "\n",
    "# **Verification Tests**\n",
    "print(\"\\nVerifying sampled data...\")\n",
    "\n",
    "# 1. Check Tensor shapes\n",
    "assert states.shape == (batch_size, num_frames, height, width), f\"Expected states shape {(batch_size, num_frames, height, width)}, got {states.shape}\"\n",
    "assert next_states.shape == (batch_size, num_frames, height, width), f\"Expected next_states shape {(batch_size, num_frames, height, width)}, got {next_states.shape}\"\n",
    "assert actions.shape == (batch_size,), f\"Expected actions shape {(batch_size,)}, got {actions.shape}\"\n",
    "assert rewards.shape == (batch_size,), f\"Expected rewards shape {(batch_size,)}, got {rewards.shape}\"\n",
    "assert dones.shape == (batch_size,), f\"Expected dones shape {(batch_size,)}, got {dones.shape}\"\n",
    "\n",
    "print(\"✔ Passed shape verification.\")\n",
    "\n",
    "# 2. Check that all values are within expected ranges\n",
    "assert torch.all(actions >= 0) and torch.all(actions < 5), \"✔ Action values out of range!\"\n",
    "assert torch.all(rewards >= -1) and torch.all(rewards <= 1), \"✔ Reward values out of range!\"\n",
    "assert torch.all((dones == 0) | (dones == 1)), \"✔ Done values must be 0 or 1!\"\n",
    "\n",
    "print(\"✔ Passed value verification.\")\n",
    "\n",
    "# 3. Check that state transitions are reasonable\n",
    "for i in range(batch_size):\n",
    "    assert not torch.equal(states[i], next_states[i]), \"✔ Sampled states and next states should not be identical!\"\n",
    "\n",
    "print(\"✔ Passed state transition verification.\")\n",
    "\n",
    "print(\"\\n🎉 Replay Buffer Verification Complete: All Tests Passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import noncentral_chisquare\n",
    "\n",
    "\n",
    "class BaseAgent(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all Deep Q-Network (DQN)-based agents.\n",
    "\n",
    "    This class provides:\n",
    "    - Initialization of neural networks (policy & target).\n",
    "    - Common hyperparameters for training (gamma, learning rate, epsilon, etc.).\n",
    "    - A method to update the target network at fixed intervals.\n",
    "    - A replay buffer for experience storage.\n",
    "\n",
    "    Subclasses must implement:\n",
    "    - `_build_model()` → Defines the neural network.\n",
    "    - `select_action()` → Chooses an action using an epsilon-greedy strategy.\n",
    "    - `train_step()` → Implements the training logic.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        frames_in_stack: int,\n",
    "        downsample_size: Tuple[int, int],\n",
    "        gamma: float,\n",
    "        lr: float,\n",
    "        epsilon: float,\n",
    "        target_update_freq: int,\n",
    "        device = None,\n",
    "        batch_size: int = 32,\n",
    "        buffer_size: int = 10_000,\n",
    "        actions_space: list[int] = [0,1,2,5]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the BaseAgent with common RL hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            state_dim (Tuple[int, int, int]): State dimensions (num_frames, height, width).\n",
    "            actions_space (list): space of (valid) actions \n",
    "                0 - Turn left\n",
    "                1 - Turn right\n",
    "                2 - Move Forward\n",
    "                5 - Toggle (open doors/close doors)\n",
    "            gamma (float): Discount factor for future rewards.\n",
    "            lr (float): Learning rate.\n",
    "            epsilon (float): Exploration probability.\n",
    "            target_update_freq (int): Number of steps between target network updates.\n",
    "        \"\"\"\n",
    "        self.actions_space = [0,1,2,5]\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        self.epsilon = epsilon\n",
    "        self.target_update_freq = target_update_freq\n",
    "\n",
    "        # Set device if not specified in argument (GPU if available, else CPU)\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Frame Stack Preprocessor initialization\n",
    "        self.frame_stack = FrameStackPreprocess(frames_in_stack, downsample_size)\n",
    "\n",
    "        \n",
    "        # Replay buffer to store past experiences\n",
    "        self.memory = ReplayBuffer(buffer_size=10_000, batch_size=32)\n",
    "\n",
    "        # Initialize policy and target networks\n",
    "        self.policy_net = self._build_model().to(self.device)\n",
    "        self.target_net = self._build_model().to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())  # Synchronize initial weights\n",
    "        self.target_net.eval()  # Target network does not require gradients\n",
    "\n",
    "        # Optimizer for training the policy network\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "        # Training step counter\n",
    "        self.train_step_count = 0\n",
    "            \n",
    "        # Tracks total reward accumulated in current episode\n",
    "        self.episode_reward = 0.0\n",
    "        # Records epsilon values over time for analysis\n",
    "        self.epsilon_history = []\n",
    "        # Counts how many times each action was selected\n",
    "        self.action_counts = {a: 0 for a in self.actions_space}\n",
    "        # Records loss values during training for monitoring\n",
    "        self.loss_history = []\n",
    "        # Records Q-values over time to analyze learning progress\n",
    "        self.q_values_history = []\n",
    "        # Records gradient norms during training for monitoring stability\n",
    "        self.grad_norms = []\n",
    "        # Counts total steps taken across all episodes\n",
    "        self.step_count = 0       \n",
    "\n",
    "    @abstractmethod\n",
    "    def _build_model(self) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Defines the neural network architecture.\n",
    "\n",
    "        This method must be implemented in subclasses to create a specific DQN model.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module: The initialized neural network.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _select_action(self, state: np.ndarray) -> int:\n",
    "        \"\"\"\n",
    "        Abstract method for selecting an action. \n",
    "\n",
    "        Subclasses must implement this method.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> int:\n",
    "        \"\"\"\n",
    "        Calls `_select_action()` and ensures the action is logged in `action_counts`.\n",
    "\n",
    "        Args:\n",
    "            state (np.ndarray): The current environment state.\n",
    "\n",
    "        Returns:\n",
    "            int: The chosen action.\n",
    "        \"\"\"\n",
    "        action = self._select_action(state)  # Calls the subclass method\n",
    "        if action in self.action_counts:\n",
    "            self.action_counts[action] += 1  # Log the action automatically\n",
    "        return action\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_step(self) -> None:\n",
    "        \"\"\"\n",
    "        Performs a single training step.\n",
    "\n",
    "        This method must be implemented in subclasses and should include:\n",
    "        - Sampling experiences from the replay buffer.\n",
    "        - Computing the Q-learning target values.\n",
    "        - Optimizing the policy network.\n",
    "        - Updating the target network when required.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def update_target_network(self) -> None:\n",
    "        \"\"\"\n",
    "        Copies weights from the policy network to the target network at fixed intervals.\n",
    "\n",
    "        The update happens every `target_update_freq` training steps.\n",
    "        \"\"\"\n",
    "        if self.train_step_count % self.target_update_freq == 0:\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(BaseAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes DQNAgent while inheriting all attributes from BaseAgent.\n",
    "        \"\"\"\n",
    "        # Call the parent constructor to initialize all attributes\n",
    "        super().__init__(*args, **kwargs)\n",
    "            \n",
    "\n",
    "\n",
    "    def _build_model(self) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Returns a dummy model (not used in RandomAgent but required by BaseAgent).\n",
    "        \"\"\"\n",
    "        return nn.Sequential(nn.Linear(1, 1))  # Dummy model\n",
    "\n",
    "    def _select_action(self, state) -> int:\n",
    "        \"\"\"\n",
    "        Selects a random action.\n",
    "        \"\"\"\n",
    "        return random.choice(self.actions_space)\n",
    "\n",
    "    def train_step(self) -> None:\n",
    "        \"\"\"\n",
    "        Dummy training step to satisfy abstract method.\n",
    "        Ensures replay buffer works correctly.\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.memory.batch_size:\n",
    "            return  # Not enough samples yet\n",
    "        \n",
    "        batch = self.memory.sample()\n",
    "        assert batch is not None, \"Sampling from memory failed\"\n",
    "        self.train_step_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests BaseAgent and RandomAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experience collection...\n",
      "Collected 0 experiences...\n",
      "Collected 100 experiences...\n",
      "Collected 200 experiences...\n",
      "Collected 300 experiences...\n",
      "Collected 400 experiences...\n",
      "Experience collection completed!\n",
      "Starting training...\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "Completed 0 training steps...\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "Completed 5 training steps...\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "Completed 10 training steps...\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "Completed 15 training steps...\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "i am inside!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Sampled batch:\n",
      "Training completed!\n",
      "RandomAgent test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "agent = RandomAgent(\n",
    "        frames_in_stack=3,\n",
    "        downsample_size=(7, 7),\n",
    "        gamma=0.99,\n",
    "        lr=0.001,\n",
    "        epsilon=1.0,\n",
    "        target_update_freq=10\n",
    "    )\n",
    "\n",
    "# Simulate random experience collection\n",
    "print(\"Starting experience collection...\")\n",
    "for i in range(500):\n",
    "    state = np.random.rand(4, 7, 7)\n",
    "    action = agent.select_action(state)\n",
    "    next_state = np.random.rand(4, 7, 7)\n",
    "    reward = random.random()\n",
    "    done = random.choice([True, False])\n",
    "    agent.memory.add(state, action, reward, next_state, done)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Collected {i} experiences...\")\n",
    "print(\"Experience collection completed!\")\n",
    "\n",
    "# Run some training steps\n",
    "print(\"Starting training...\")\n",
    "for i in range(20):\n",
    "    agent.train_step()\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Completed {i} training steps...\")\n",
    "print(\"Training completed!\")\n",
    "\n",
    "print(\"RandomAgent test completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished! Total Reward: 0 Steps: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <video width=\"640\" height=\"480\" controls>\n",
       "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "  </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_filename = Path.joinpath(WORK_DIR, \"videos/vid.mp4\")\n",
    "env, obs = create_multiroom_env(2, 4, seed=23)\n",
    "env.unwrapped.max_steps=100\n",
    "truncated = False\n",
    "total_reward=0\n",
    "\n",
    "# Evaluation\n",
    "with imageio.get_writer(video_filename, fps=16) as video:\n",
    "  obs, _ = env.reset()\n",
    "  done = False\n",
    "  step = 0\n",
    "  while not (done or truncated):\n",
    "      action = agent.select_action(None)\n",
    "      obs, reward, done, truncated  , _ = env.step(action)\n",
    "      total_reward += reward\n",
    "      next_obs = obs\n",
    "      video.append_data(env.render())\n",
    "\n",
    "      agent.memory.add(obs, action, reward, next_obs, done)\n",
    "      step += 1\n",
    "\n",
    "      if done or truncated:\n",
    "          print(\"Episode finished!\", \"Total Reward:\", total_reward, \"Steps:\", step)\n",
    "          break\n",
    "embed_mp4(video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.action_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQNAgent(BaseAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes DQNAgent while inheriting all attributes from BaseAgent.\n",
    "        \"\"\"\n",
    "        # Call the parent constructor to initialize all attributes\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Define policy and target networks (BaseAgent already initializes other attributes)\n",
    "        self.policy_net = self._build_model().to(self.device)\n",
    "        self.target_net = self._build_model().to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())  # Sync weights\n",
    "        self.target_net.eval()  # Target net does not require gradients\n",
    "\n",
    "        # Define optimizer\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.lr)  \n",
    "        \n",
    "\n",
    "    def _build_model(self) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Defines the neural network model for the DQN agent.\n",
    "        \"\"\"\n",
    "        return QNet((self.frame_stack.num_frames,*self.frame_stack.downsample_size),\n",
    "                    len(self.actions_space)).to(self.device)\n",
    "\n",
    "    def _select_action(self, state: np.ndarray) -> int:\n",
    "        \"\"\"\n",
    "        Selects an action using an epsilon-greedy strategy.\n",
    "        \"\"\"\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(self.actions_space)  # Explore\n",
    "        else:\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                e_tensor\n",
    "            return torch.argmax(q_values, dim=1).item()  # Exploit\n",
    "\n",
    "    def train_step(self) -> None:\n",
    "        \"\"\"\n",
    "        Performs a single training step: samples from the replay buffer, computes the loss, and updates the network.\n",
    "        \"\"\"\n",
    "        print(\"inside train step\")\n",
    "        if len(self.memory) < self.memory.batch_size:\n",
    "            return  # Not enough samples\n",
    "        \n",
    "\n",
    "        # print(\"enough samples - lets try to train here something\")\n",
    "        states, actions, rewards, next_states, dones = self.memory.sample()\n",
    "        # print(\"Actions Shape:\", np.array(actions).shape)\n",
    "        # print(\"Actions Values:\", actions.tolist())  # Convert to list for readability\n",
    "        # print(\"Min action:\", actions.min(), \"Max action:\", actions.max())\n",
    "        # print(\"Action space:\", self.actions_space)\n",
    "\n",
    "\n",
    "        # print(\"actions:\", actions)\n",
    "        # # raise ValueError(\"gsfdgsdfgdsfgdfgdfg\")\n",
    "        # # print(\"Debug Shapes:\")\n",
    "        # # print(\"States:\", np.array(states).shape)\n",
    "        # # print(\"Actions:\", np.array(actions).shape)\n",
    "        # # print(actions)\n",
    "        # # print(\"Actions Shape:\", np.array(actions).shape)\n",
    "        # # print(\"Actions Values:\", actions.tolist())  # Convert to list for readability\n",
    "        # # print(\"Min action:\", actions.min(), \"Max action:\", actions.max())\n",
    "        # # print(\"Action space:\", self.actions_space)\n",
    "        # # assert actions.min() >= 0 and actions.max() < len(self.actions_space), \"Invalid action index detected!\"\n",
    "        # print(\"Rewards:\", np.array(rewards).shape)\n",
    "        # print(\"Next States:\", np.array(next_states).shape)\n",
    "        # print(\"Dones:\", np.array(dones).shape)\n",
    "\n",
    "        print(\"start insertion to tensor\")\n",
    "        states, actions, rewards, next_states, dones = (\n",
    "            states.to(self.device),\n",
    "            actions.to(self.device),\n",
    "            rewards.to(self.device),\n",
    "            next_states.to(self.device),\n",
    "            dones.to(self.device),\n",
    "        )\n",
    "\n",
    "        # Debug: Check device placement\n",
    "        print(f\"Device of tensors - states: {states.device}, actions: {actions.device}, rewards: {rewards.device}, next_states: {next_states.device}, dones: {dones.device}\")\n",
    "\n",
    "\n",
    "        # 🔹 Map actions from {0,1,2,5} → {0,1,2,3} to be valid indices for .gather()\n",
    "        action_mapping = {0: 0, 1: 1, 2: 2, 5: 3}  \n",
    "        actions_mapped = actions.clone()  # Clone to avoid modifying the original tensor\n",
    "        for key, value in action_mapping.items():\n",
    "            actions_mapped[actions == key] = value\n",
    "\n",
    "        # Compute Q-values for current states\n",
    "        q_values = self.policy_net(states).gather(1, actions_mapped.unsqueeze(1)).squeeze(1)        \n",
    "\n",
    "        # Compute target Q-values\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_net(next_states).max(1)[0]\n",
    "            target_q_values = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "        \n",
    "        # Compute loss and update the model\n",
    "        loss = nn.MSELoss()(q_values, target_q_values)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update training step count\n",
    "        self.train_step_count += 1\n",
    "        \n",
    "        # Update target network if needed\n",
    "        self.update_target_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m action_space \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m]  \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize DQNAgent\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mDQNAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframes_in_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframes_in_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownsample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownsample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_update_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_update_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactions_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Environment setup\u001b[39;00m\n\u001b[0;32m     26\u001b[0m num_episodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m, in \u001b[0;36mDQNAgent.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mInitializes DQNAgent while inheriting all attributes from BaseAgent.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Call the parent constructor to initialize all attributes\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define policy and target networks (BaseAgent already initializes other attributes)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_model()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[19], line 66\u001b[0m, in \u001b[0;36mBaseAgent.__init__\u001b[1;34m(self, frames_in_stack, downsample_size, gamma, lr, epsilon, target_update_freq, device, batch_size, buffer_size, actions_space)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;241m=\u001b[39m ReplayBuffer(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10_000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Initialize policy and target networks\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_model()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net\u001b[38;5;241m.\u001b[39mstate_dict())  \u001b[38;5;66;03m# Synchronize initial weights\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m, in \u001b[0;36mDQNAgent._build_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_build_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    Defines the neural network model for the DQN agent.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m---> 24\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions_space\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\minigrid-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\minigrid-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\minigrid-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\minigrid-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\minigrid-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "env, obs = create_multiroom_env(num_rooms=2, max_room_size=5, seed=5)\n",
    "\n",
    "\n",
    "frames_in_stack = 3  \n",
    "downsample_size = (14, 14) \n",
    "gamma = 0.99  \n",
    "learning_rate = 1e-3  \n",
    "epsilon = 1.0  \n",
    "target_update_freq = 10 \n",
    "action_space = [0, 1, 2, 5]  \n",
    "\n",
    "# Initialize DQNAgent\n",
    "agent = DQNAgent(\n",
    "    frames_in_stack=frames_in_stack,\n",
    "    downsample_size=downsample_size,\n",
    "    gamma=gamma,\n",
    "    lr=learning_rate,\n",
    "    epsilon=epsilon,\n",
    "    target_update_freq=target_update_freq,\n",
    "    actions_space=action_space, \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "# Environment setup\n",
    "num_episodes = 40\n",
    "max_steps_per_episode = 100  # Limit steps per episode\n",
    "batch_size = 32  # Training starts after collecting 32 samples\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "\n",
    "    stacked_frame = agent.frame_stack.reset(state)\n",
    "    print(f\"stacked_frame shape: {stacked_frame.shape}\")\n",
    "                          \n",
    "\n",
    "    episode_reward = 0\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        print(episode, step)\n",
    "        # Select action using ε-greedy (already implemented inside select_action)\n",
    "        action = agent.select_action(stacked_frame)\n",
    "        # Step in environment\n",
    "        next_state, reward, done, truncated, _ = env.step(action)\n",
    "        next_state_stacked = agent.frame_stack.update(next_state)  # Preprocess next state\n",
    "\n",
    "        # print(f\"Adding to memory at step {step} of episode {episode}:\")\n",
    "        # print(f\"state shape: {state.shape}, action: {action}, reward: {reward}, next_state shape: {next_state_stacked.shape}, done: {done}\")\n",
    "\n",
    "        agent.memory.add(stacked_frame, action, reward, next_state_stacked, done)\n",
    "\n",
    "         # Start training only after 32 samples in replay buffer\n",
    "        if len(agent.memory) >= batch_size:\n",
    "            batch = agent.memory.sample()\n",
    "            agent.train_step()\n",
    "\n",
    "        # Update state and track reward\n",
    "        state = next_state_stacked\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "            # Store episode reward\n",
    "    episode_rewards.append(episode_reward)\n",
    "    print(f\"Episode {episode+1}: Reward = {episode_reward}\")\n",
    "\n",
    "# Plot rewards over time\n",
    "plt.plot(episode_rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Agent Learning Progress\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "minigrid-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
